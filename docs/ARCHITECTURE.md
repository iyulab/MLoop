# MLoop Architecture Documentation

## Table of Contents

1. [Overview](#1-overview)
2. [Architectural Principles](#2-architectural-principles)
3. [Process Model](#3-process-model)
4. [System Architecture](#4-system-architecture)
5. [Layer Design](#5-layer-design)
6. [Project Structure](#6-project-structure)
7. [Data Models](#7-data-models)
8. [Core Workflows](#8-core-workflows)
9. [Configuration Management](#9-configuration-management)
10. [Git Integration](#10-git-integration)
11. [Technology Stack](#11-technology-stack)
12. [Testing Strategy](#12-testing-strategy)
13. [Long-Running Tasks](#13-long-running-tasks)
14. [Extensibility System](#14-extensibility-system)
15. [Future Extensibility](#15-future-extensibility)

---

## 1. Overview

MLoop is a lightweight MLOps platform built on ML.NET, designed with a **filesystem-first** and **multi-process casual** approach that emphasizes simplicity, transparency, and Git compatibility.

### 1.1 Core Mission

**"Excellent MLOps with Minimum Cost"**

MLoop enables anyone to achieve production-quality ML models with minimal coding and ML expertise, while maintaining flexibility for advanced customization. This is accomplished through:

1. **Minimal Development Cost**: 3-command workflow (`init` â†’ `train` â†’ `predict`) vs traditional multi-week ML projects
2. **Minimal Knowledge Cost**: AutoML eliminates need for ML expertise (AI assistance via mloop-mcp)
3. **Minimal Operational Cost**: Filesystem-based MLOps, no infrastructure complexity
4. **Maximum Value**: Production-ready models with optional extensibility for expert users

### 1.2 Design Philosophy

**Convention Over Configuration**
- Filesystem-based contracts: Drop CSV in `datasets/`, get trained model
- Zero configuration required for 90% of use cases
- Git-friendly MLOps: All state as files, no databases
- Intelligent defaults that work immediately

**AutoML-First, Minimal Coding**
- One command trains production-ready models
- Automatic algorithm selection via ML.NET AutoML
- Optional FilePrepper integration for complex preprocessing
- No manual feature engineering unless user chooses to customize

**AI Integration via MCP (External)**
- AI agents access MLoop through mloop-mcp (separate repository)
- "AI uses MLoop" philosophy (not "MLoop contains AI")
- See docs/ECOSYSTEM.md for MLoop ecosystem architecture

**Extensibility Through Dynamic Scripting**
- Optional C# scripts for custom logic (hooks, metrics, preprocessing)
- Automatic compilation and caching for performance
- Zero overhead when extensions aren't used (<1ms impact)
- Full IDE support (IntelliSense, debugging, type safety)

### 1.3 Technical Design Principles

- **Filesystem-First**: All state managed as files, perfect Git integration
- **Multi-Process Casual**: Each command runs independently, no daemon required
- **Zero Configuration**: Usable immediately with minimal setup
- **Layer Separation**: Clear separation between CLI, Core, and Storage
- **Lightweight**: Independent operation without complex dependencies
- **AutoML-Driven**: Automatic model selection over manual tuning

### 1.4 Target Use Cases

**âœ… Suitable For:**
- Medium datasets (< 1GB)
- Standard ML problems (classification, regression)
- Fast prototyping and iteration
- .NET ecosystem projects
- Intermittent ML workloads (train â†’ exit, predict â†’ exit)

**âŒ Not Suitable For:**
- Complex feature engineering needs
- State-of-the-art performance requirements
- Large-scale datasets (> 10GB)
- Real-time learning/retraining
- Always-on service requirements

---

## 2. Architectural Principles

### 2.1 SOLID Principles

- **Single Responsibility**: Each component has one reason to change
- **Open/Closed**: Open for extension, closed for modification
- **Liskov Substitution**: Derived classes substitutable for base classes
- **Interface Segregation**: No dependencies on unused interfaces
- **Dependency Inversion**: Depend on abstractions, not concretions

### 2.2 Design Philosophy

#### Lightweight First
- User handles data preprocessing
- Accept clean, preprocessed data only
- Focus on AutoML capabilities
- Minimal dependency footprint
- **No daemon or background service management**

#### Usability Over Everything
- AutoML-centric workflow
- Speed over precision for prototyping
- 3-step workflow: `init â†’ train â†’ predict`
- Sensible defaults for everything
- **Simple process lifecycle: Start â†’ Execute â†’ Exit**

#### Filesystem-First MLOps
- All state persisted as files
- Git-friendly structure
- No external databases or services
- Human-readable formats (JSON, YAML)
- **Natural multi-process isolation via filesystem**

---

## 3. Process Model

### 3.1 Multi-Process Casual Design

**Core Concept**: Each MLoop command runs as an **independent process** that exits when complete.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Traditional Daemon Model (NOT MLoop)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  $ mloop daemon start      â† Start service     â”‚
â”‚  $ mloop train data.csv    â† Submit to daemon  â”‚
â”‚  $ mloop daemon stop       â† Stop service      â”‚
â”‚                                                 â”‚
â”‚  âŒ Complex: Port management, PID files, etc.  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLoop Multi-Process Model (Phase 1)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  $ mloop train data.csv    â† Start process     â”‚
â”‚      [Training... 5 min]                        â”‚
â”‚      âœ… Complete, exit                          â”‚
â”‚                                                 â”‚
â”‚  $ mloop predict model.zip data.csv             â”‚
â”‚      [Predicting... 10 sec]                     â”‚
â”‚      âœ… Complete, exit                          â”‚
â”‚                                                 â”‚
â”‚  âœ… Simple: No daemon, no management            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Why Multi-Process Casual?

#### Perfect for MLoop's Usage Pattern

**MLoop workloads are intermittent, not continuous:**
```bash
# Typical workflow
$ mloop train data.csv --label target
  â†’ Train for 10 minutes â†’ Exit

$ mloop evaluate exp-001/model.zip test.csv
  â†’ Evaluate for 30 seconds â†’ Exit

$ mloop predict exp-001/model.zip new-data.csv
  â†’ Predict for 10 seconds â†’ Exit
```

**vs Docker (continuous service):**
```bash
$ docker run -d my-service  # Daemon mode
$ docker ps                 # Persistent service
$ docker stop my-service    # Explicit stop
```

MLoop doesn't need to stay running between operations.

#### Advantages

| Aspect | Multi-Process | Background Daemon |
|--------|---------------|-------------------|
| **Simplicity** | â­â­â­â­â­ Minimal | â­â­ Complex |
| **Management** | âœ… None required | âŒ start/stop/status/restart |
| **Isolation** | âœ… Perfect (per-process) | âš ï¸ Shared daemon |
| **Concurrent Jobs** | âœ… Natural support | âš ï¸ Requires job queue |
| **Debugging** | âœ… Direct terminal output | âŒ Log file inspection |
| **Port Conflicts** | âœ… N/A | âŒ Possible |
| **Process Cleanup** | âœ… OS handles | âŒ Manual management |
| **Usage Pattern Fit** | âœ… Perfect match | âŒ Over-engineering |

#### Disadvantages (and Mitigation)

**Concern**: "What about long-running training jobs?"

**Solution**: Use standard Unix tools (see [Section 13](#13-long-running-tasks))
```bash
# Option 1: nohup
$ nohup mloop train data.csv --label target --time 3600 &

# Option 2: screen/tmux
$ screen -S ml-training
$ mloop train data.csv --label target --time 3600
# Ctrl+A, D to detach
```

### 3.3 Exception: mloop serve

The `mloop serve` command is the **only exception** that maintains a server process:

```bash
$ mloop serve models/production/model.zip --port 5000
ğŸš€ MLoop API Server
   Listening on: http://localhost:5000
   Swagger UI: http://localhost:5000/swagger

   Press Ctrl+C to stop

# Server process stays alive
# Standard web server pattern
# User explicitly controls lifecycle
```

**Why this is different:**
- API serving requires persistent HTTP listener
- User explicitly requests long-running service
- Standard web server behavior (like `dotnet run`)
- Simple lifecycle: Start with command, stop with Ctrl+C

**No daemon management needed:**
- No background service
- No `mloop serve start/stop/status`
- Just run in terminal or use `nohup` if needed

### 3.4 Concurrent Execution

**Natural isolation via filesystem:**

```bash
# Terminal 1: Project A
$ cd ~/projects/sentiment-analyzer
$ mloop train data.csv --label sentiment
  â†’ experiments/exp-001/

# Terminal 2: Project B (concurrent!)
$ cd ~/projects/price-predictor
$ mloop train data.csv --label price
  â†’ experiments/exp-001/

# No conflicts!
# Each project has independent .mloop/ directory
# Filesystem provides natural isolation
```

**Same project, different experiments:**
```bash
# Terminal 1
$ mloop train data.csv --label target --time 300
  â†’ experiments/exp-001/

# Terminal 2 (while #1 is running)
$ mloop train data.csv --label target --time 600 --metric f1
  â†’ experiments/exp-002/

# Works perfectly!
# Each gets unique experiment ID
# No shared state, no locks needed
```

---

## 4. System Architecture

### 4.1 Layered Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Interface Layer (CLI)                      â”‚
â”‚                                                              â”‚
â”‚  Each command execution = New process instance              â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Command    â”‚  â”‚  Validation  â”‚  â”‚   Progress   â”‚      â”‚
â”‚  â”‚   Parsing    â”‚  â”‚   & Error    â”‚  â”‚   Reporter   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ In-Process Method Calls
                         â”‚ (No IPC, No gRPC)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core Engine Layer                         â”‚
â”‚                                                              â”‚
â”‚  Instantiated per command execution                          â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Training   â”‚  â”‚  Prediction  â”‚  â”‚  Evaluation  â”‚      â”‚
â”‚  â”‚   Engine     â”‚  â”‚   Engine     â”‚  â”‚   Engine     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   AutoML     â”‚  â”‚    Model     â”‚  â”‚  Experiment  â”‚      â”‚
â”‚  â”‚   Runner     â”‚  â”‚   Registry   â”‚  â”‚    Store     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚         FileSystem Manager                       â”‚        â”‚
â”‚  â”‚         (Storage Abstraction)                    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ File I/O Operations
                         â”‚ (Stateless, thread-safe)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Storage Layer                             â”‚
â”‚                                                              â”‚
â”‚  Filesystem Structure (Provides isolation)                   â”‚
â”‚  â”œâ”€â”€ .mloop/          (Project metadata)                    â”‚
â”‚  â”œâ”€â”€ experiments/     (Training results)                    â”‚
â”‚  â”œâ”€â”€ models/          (Promoted models)                     â”‚
â”‚  â”œâ”€â”€ data/            (User data)                           â”‚
â”‚  â””â”€â”€ outputs/         (Predictions, reports)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Process Lifecycle:
1. User runs command â†’ New process starts
2. CLI parses â†’ Core executes â†’ Storage persists
3. Command completes â†’ Process exits
4. No background service, no daemon
```

### 4.2 Process Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  mloop train data.csv --label target             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Process Start â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Load Config   â”‚
         â”‚  Find Project  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Execute Core  â”‚
         â”‚  (Training)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Save Results  â”‚
         â”‚  to Filesystem â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Process Exit   â”‚
         â”‚  (Return code) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

No state preserved between executions
Next command starts fresh process
```

### 4.3 State Management

**All state lives in filesystem, not in memory:**

```csharp
// âŒ ANTI-PATTERN: In-memory state (daemon model)
public class MLoopDaemon
{
    private Dictionary<string, TrainingJob> _activeJobs;
    private ModelCache _modelCache;
    // State lost on process exit!
}

// âœ… MLoop Pattern: Filesystem state
public class TrainingEngine
{
    public async Task<TrainingResult> TrainAsync(TrainingConfig config)
    {
        // 1. Read config from filesystem
        var projectConfig = await _fileSystem.LoadConfigAsync();

        // 2. Execute training
        var result = await _autoML.TrainAsync(config);

        // 3. Persist everything to filesystem
        await _experimentStore.SaveAsync(result);

        // 4. Process exits, state preserved in files
        return result;
    }
}
```

**Benefits:**
- âœ… No state synchronization between processes
- âœ… Crash-safe (filesystem is durable)
- âœ… Easy to inspect state (`cat experiments/exp-001/metadata.json`)
- âœ… Natural versioning with Git

---

## 5. Layer Design

### 5.1 User Interface Layer (CLI)

**Responsibilities:**
- Parse and validate user commands
- Instantiate Core Engine components
- Provide real-time user feedback (progress bars, logs)
- Format output (tables, JSON, text)
- Exit with appropriate return code

**Key Components:**
- **Command Parser**: System.CommandLine for parsing
- **Validator**: Input validation and error handling
- **Progress Reporter**: Spectre.Console for visual feedback
- **Output Formatter**: Multiple output format support

**Design Guidelines:**
- Keep layer thin (no business logic)
- Direct method calls to Core Engine (no IPC)
- Focus on user experience optimization
- Synchronous execution (await completion)

**Example Implementation:**
```csharp
public class TrainCommand : Command
{
    public TrainCommand() : base("train", "Train a model using AutoML")
    {
        var dataFileArg = new Argument<string>("data-file");
        var labelOption = new Option<string>("--label");

        AddArgument(dataFileArg);
        AddOption(labelOption);

        this.SetHandler(ExecuteAsync, dataFileArg, labelOption);
    }

    private async Task<int> ExecuteAsync(string dataFile, string label)
    {
        try
        {
            // 1. Validate inputs
            if (!File.Exists(dataFile))
                return Error("Data file not found");

            // 2. Find project root
            var projectRoot = ProjectDiscovery.FindRoot();

            // 3. Instantiate Core Engine (in-process)
            var engine = new TrainingEngine(projectRoot);

            // 4. Execute training
            var result = await engine.TrainAsync(new TrainingConfig
            {
                DataFile = dataFile,
                LabelColumn = label
            });

            // 5. Display results
            DisplayResults(result);

            // 6. Exit with success
            return 0;
        }
        catch (Exception ex)
        {
            Error(ex.Message);
            return 1;
        }
        // Process exits after return
    }
}
```

### 5.2 Core Engine Layer

**Responsibilities:**
- All ML-related business logic
- Filesystem state management
- ML.NET and AutoML orchestration
- Experiment tracking and model registry

**Key Components:**

#### Training Engine
```csharp
namespace MLoop.Core.AutoML;

public interface ITrainingEngine
{
    Task<TrainingResult> TrainAsync(
        TrainingConfig config,
        IProgress<TrainingProgress> progress,
        CancellationToken cancellationToken);
}

public class TrainingEngine : ITrainingEngine
{
    private readonly IFileSystemManager _fileSystem;
    private readonly IAutoMLRunner _autoML;
    private readonly IExperimentStore _experiments;

    public async Task<TrainingResult> TrainAsync(
        TrainingConfig config,
        IProgress<TrainingProgress> progress,
        CancellationToken cancellationToken)
    {
        // 1. Generate experiment ID
        var experimentId = await _experiments.GenerateIdAsync();

        // 2. Run AutoML
        var mlResult = await _autoML.RunAsync(config, progress, cancellationToken);

        // 3. Save results to filesystem
        await _experiments.SaveAsync(experimentId, mlResult);

        // 4. Return (process will exit)
        return new TrainingResult
        {
            ExperimentId = experimentId,
            BestTrainer = mlResult.BestTrainer,
            Metrics = mlResult.Metrics
        };
    }
}
```

#### Prediction Engine
```csharp
namespace MLoop.Core.Models;

public interface IPredictionEngine
{
    Task<PredictionResult> PredictAsync(
        string modelPath,
        IDataSource dataSource,
        CancellationToken cancellationToken);
}
```

#### Evaluation Engine
```csharp
namespace MLoop.Core.Evaluation;

public interface IEvaluator
{
    Task<EvaluationResult> EvaluateAsync(
        string modelPath,
        IDataSource testData,
        CancellationToken cancellationToken);
}
```

**Thread Safety:**
- Each process instance is single-threaded for commands
- No shared state between processes
- Filesystem operations use OS-level locking
- No need for distributed locks or semaphores

### 5.3 Storage Layer (Filesystem)

**Responsibilities:**
- Persist all project data as files
- Provide Git-friendly structure
- Use human-readable formats (JSON, YAML)
- Enable natural multi-process isolation

**Thread-Safe Operations:**
```csharp
public class FileSystemManager : IFileSystemManager
{
    // Atomic operations via OS
    public async Task<string> GenerateExperimentIdAsync()
    {
        // Read-Modify-Write with retry
        for (int retry = 0; retry < 3; retry++)
        {
            try
            {
                var index = await ReadIndexAsync();
                var newId = $"exp-{index.NextId:D3}";
                index.NextId++;
                await WriteIndexAsync(index);
                return newId;
            }
            catch (IOException)
            {
                // Another process modified file, retry
                await Task.Delay(100);
            }
        }
        throw new ConcurrencyException("Failed to generate ID");
    }
}
```

---

## 6. Project Structure

### 6.1 Development Project Structure

MLoop is organized into **6 separate projects** with clear separation of concerns:

```
MLoop/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ MLoop.sln                        # .NET 10 Solution
â”‚   â”‚
â”‚   â”œâ”€â”€ MLoop.Extensibility/             # Extension interfaces (no dependencies)
â”‚   â”‚   â”œâ”€â”€ Preprocessing/
â”‚   â”‚   â”‚   â””â”€â”€ IPreprocessingScript.cs  # Custom preprocessing interface
â”‚   â”‚   â”œâ”€â”€ Hooks/
â”‚   â”‚   â”‚   â””â”€â”€ IHook.cs                 # Lifecycle hook interface
â”‚   â”‚   â””â”€â”€ Metrics/
â”‚   â”‚       â””â”€â”€ ICustomMetric.cs         # Custom metric interface
â”‚   â”‚
â”‚   â”œâ”€â”€ MLoop.Core/                      # Core ML engine
â”‚   â”‚   â”œâ”€â”€ AutoML/                      # ML.NET AutoML wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ TrainingEngine.cs
â”‚   â”‚   â”‚   â””â”€â”€ TrainingConfig.cs
â”‚   â”‚   â”œâ”€â”€ Data/                        # Data loading, encoding detection
â”‚   â”‚   â”‚   â”œâ”€â”€ DataLoaderFactory.cs
â”‚   â”‚   â”‚   â””â”€â”€ CsvHelperImpl.cs
â”‚   â”‚   â”œâ”€â”€ Preprocessing/               # FilePrepper integration
â”‚   â”‚   â”œâ”€â”€ Scripting/                   # C# script compilation/execution
â”‚   â”‚   â”œâ”€â”€ Hooks/                       # Hook execution
â”‚   â”‚   â”œâ”€â”€ Metrics/                     # Metric processing
â”‚   â”‚   â””â”€â”€ Models/                      # Domain models (Experiment, etc.)
â”‚   â”‚
â”‚   â”œâ”€â”€ MLoop.CLI/                       # Command-line interface
â”‚   â”‚   â”œâ”€â”€ Commands/                    # CLI commands
â”‚   â”‚   â”‚   â”œâ”€â”€ InitCommand.cs          # mloop init
â”‚   â”‚   â”‚   â”œâ”€â”€ TrainCommand.cs         # mloop train
â”‚   â”‚   â”‚   â”œâ”€â”€ PredictCommand.cs       # mloop predict
â”‚   â”‚   â”‚   â”œâ”€â”€ EvaluateCommand.cs      # mloop evaluate
â”‚   â”‚   â”‚   â”œâ”€â”€ ListCommand.cs          # mloop list
â”‚   â”‚   â”‚   â”œâ”€â”€ PromoteCommand.cs       # mloop promote
â”‚   â”‚   â”‚   â”œâ”€â”€ ServeCommand.cs         # mloop serve (launches API)
â”‚   â”‚   â”‚   â”œâ”€â”€ DockerCommand.cs        # mloop docker
â”‚   â”‚   â”‚   â””â”€â”€ InfoCommand.cs          # mloop info
â”‚   â”‚   â”œâ”€â”€ Infrastructure/              # Console output, DI setup
â”‚   â”‚   â””â”€â”€ Templates/                   # Dockerfile templates
â”‚   â”‚
â”‚   â”œâ”€â”€ MLoop.API/                       # REST API server (ASP.NET Core)
â”‚   â”‚   â”œâ”€â”€ Program.cs                   # Minimal API endpoints
â”‚   â”‚   â””â”€â”€ appsettings.json             # API configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ MLoop.DataStore/                 # Prediction logging & feedback (MLOps)
â”‚   â”‚   â””â”€â”€ Interfaces/
â”‚   â”‚       â”œâ”€â”€ IPredictionLogger.cs     # Prediction logging interface
â”‚   â”‚       â”œâ”€â”€ IFeedbackCollector.cs    # Ground truth feedback collection
â”‚   â”‚       â””â”€â”€ IDataSampler.cs          # Production data sampling
â”‚   â”‚
â”‚   â””â”€â”€ MLoop.Ops/                       # MLOps automation
â”‚       â””â”€â”€ Interfaces/
â”‚           â”œâ”€â”€ IRetrainingTrigger.cs    # Retraining condition evaluation
â”‚           â”œâ”€â”€ IModelComparer.cs        # Model performance comparison
â”‚           â””â”€â”€ IPromotionManager.cs     # Automated model promotion
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ MLoop.Core.Tests/
â”‚   â”œâ”€â”€ MLoop.API.Tests/
â”‚   â””â”€â”€ MLoop.Pipeline.Tests/
â”‚
â”œâ”€â”€ examples/                            # Example projects
â”‚   â”œâ”€â”€ customer-churn/
â”‚   â”œâ”€â”€ equipment-anomaly-detection/
â”‚   â””â”€â”€ tutorials/
â”‚
â”œâ”€â”€ docs/                                # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md                  # This file
â”‚   â”œâ”€â”€ GUIDE.md                         # User guide
â”‚   â””â”€â”€ ECOSYSTEM.md                     # MLoop ecosystem overview
â”‚
â”œâ”€â”€ mcp/                                 # [Submodule] mloop-mcp (MCP Server)
â”‚   â””â”€â”€ (https://github.com/iyulab/mloop-mcp)
â”‚
â”œâ”€â”€ studio/                              # [Submodule] mloop-studio (Web Platform)
â”‚   â””â”€â”€ (https://github.com/iyulab/mloop-studio)
â”‚
â”œâ”€â”€ Directory.Build.props                # Central package management
â”œâ”€â”€ Directory.Packages.props             # Package versions
â””â”€â”€ .gitignore
```

### 6.2 Project Dependencies

```
MLoop.Extensibility  â† (interfaces only, no dependencies)
        â†‘
    MLoop.Core       â† ML.NET, FilePrepper
        â†‘
    â”Œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â”‚           â”‚
    â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   â”‚   â”‚               â”‚
MLoop.CLI  MLoop.API  MLoop.DataStore  MLoop.Ops
    â”‚                       â”‚              â”‚
    â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€ (CLI launches API via ServeCommand)

Note: DataStore/Ops are MLOps extensions (separate from core CLI)
```

| Project | Role | Key Dependencies |
|---------|------|------------------|
| MLoop.Extensibility | Extension interfaces | None |
| MLoop.Core | ML engine | ML.NET, FilePrepper |
| MLoop.CLI | CLI tool (`mloop`) | System.CommandLine, Spectre.Console |
| MLoop.API | REST API server | ASP.NET Core, Serilog |
| MLoop.DataStore | Prediction logging & feedback | MLoop.Core |
| MLoop.Ops | MLOps automation | MLoop.Core |

### 6.3 User Project Structure (Multi-Model)

MLoop v0.2.0+ supports **multiple models** within a single project. When users run `mloop init my-project --task binary-classification`:

```
my-project/
â”œâ”€â”€ .mloop/                              # Internal (Git ignored)
â”‚   â”œâ”€â”€ config.json                      # Project settings
â”‚   â””â”€â”€ models.json                      # Model name registry
â”‚
â”œâ”€â”€ mloop.yaml                           # User config (Git)
â”œâ”€â”€ .gitignore                           # MLoop gitignore
â”œâ”€â”€ README.md                            # Project guide
â”‚
â”œâ”€â”€ datasets/                            # Training data (Git)
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ predict.csv
â”‚
â”œâ”€â”€ models/                              # Per-model directories
â”‚   â”œâ”€â”€ default/                         # Default model (--name omitted)
â”‚   â”‚   â”œâ”€â”€ staging/                     # Experiments
â”‚   â”‚   â”‚   â”œâ”€â”€ exp-001/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ model.zip           # Trained model (ignored)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ experiment.json     # Experiment metadata (Git)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ training.log        # Training log (ignored)
â”‚   â”‚   â”‚   â””â”€â”€ exp-002/
â”‚   â”‚   â”œâ”€â”€ production/                  # Promoted model
â”‚   â”‚   â”‚   â”œâ”€â”€ model.zip               # (ignored)
â”‚   â”‚   â”‚   â””â”€â”€ metadata.json           # (Git)
â”‚   â”‚   â””â”€â”€ registry.json               # Model-specific registry
â”‚   â”‚
â”‚   â”œâ”€â”€ churn/                           # Named model example
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ production/
â”‚   â”‚   â””â”€â”€ registry.json
â”‚   â”‚
â”‚   â””â”€â”€ revenue/                         # Another named model
â”‚       â”œâ”€â”€ staging/
â”‚       â”œâ”€â”€ production/
â”‚       â””â”€â”€ registry.json
â”‚
â””â”€â”€ predictions/                         # Prediction outputs
    â”œâ”€â”€ default/
    â”œâ”€â”€ churn/
    â””â”€â”€ revenue/
```

### 6.4 Multi-Model Configuration

#### mloop.yaml Schema

```yaml
# Project-level settings
project: customer-analytics

# Model definitions
models:
  default:                      # Required: default model
    task: binary-classification
    label: Churn
    description: Customer churn prediction
    training:
      time_limit_seconds: 300
      metric: F1Score
      test_split: 0.2

  revenue:                      # Optional: named models
    task: regression
    label: Revenue
    description: Revenue prediction model
    training:
      time_limit_seconds: 600
      metric: RSquared

# Shared data settings
data:
  train: datasets/train.csv
  test: datasets/test.csv
```

### 6.5 Multi-Model CLI Usage

```bash
# Default model (--name omitted)
mloop train datasets/train.csv Churn --time 60
mloop predict
mloop promote exp-001

# Named model
mloop train datasets/train.csv Revenue --name revenue --time 60
mloop predict --name revenue
mloop promote exp-001 --name revenue

# List experiments across models
mloop list                    # All models
mloop list --name default     # Specific model

# Multi-model serving
mloop serve                   # Serves all production models
# Routes: /predict?name=default, /predict?name=revenue
```

---

## 7. Data Models

### 7.1 Internal Management Files

#### .mloop/config.json
```json
{
  "project": "my-ml-project",
  "version": "0.2.0",
  "created_at": "2025-12-08T10:00:00Z",
  "mloop_version": "0.2.0"
}
```

#### .mloop/models.json (Model Registry Index)
```json
{
  "models": {
    "default": {
      "created_at": "2025-12-08T10:00:00Z",
      "task": "binary-classification",
      "label": "Churn",
      "experiment_count": 5,
      "production_experiment": "exp-003"
    },
    "revenue": {
      "created_at": "2025-12-08T11:00:00Z",
      "task": "regression",
      "label": "Revenue",
      "experiment_count": 3,
      "production_experiment": "exp-002"
    }
  }
}
```

#### models/{name}/registry.json (Per-Model Registry)
```json
{
  "next_id": 6,
  "production": {
    "experiment_id": "exp-003",
    "promoted_at": "2025-12-08T14:00:00Z",
    "metrics": {
      "F1Score": 0.897,
      "Accuracy": 0.913
    }
  }
}
```

### 7.2 Experiment Files

#### models/{name}/staging/exp-XXX/experiment.json
```json
{
  "model_name": "default",
  "experiment_id": "exp-001",
  "timestamp": "2025-12-08T12:00:00Z",
  "status": "completed",
  "task": "binary-classification",
  "data": {
    "train_file": "datasets/train.csv",
    "rows": 10000,
    "features": 15,
    "label": "Churn"
  },
  "config": {
    "time_limit_seconds": 300,
    "metric": "F1Score",
    "test_split": 0.2
  },
  "result": {
    "best_trainer": "LightGbmBinary",
    "training_time_seconds": 287,
    "metrics": {
      "F1Score": 0.897,
      "Accuracy": 0.913,
      "AUC": 0.945
    }
  },
  "versions": {
    "mlnet": "5.0.0",
    "mloop": "0.2.0"
  }
}
```

### 7.3 User Configuration File

#### mloop.yaml (Multi-Model Format)
```yaml
# MLoop Project Configuration (v0.2.0+)
project: customer-analytics

# Model definitions
models:
  default:
    task: binary-classification
    label: Churn
    description: Customer churn prediction model
    training:
      time_limit_seconds: 300
      metric: F1Score
      test_split: 0.2

  revenue:
    task: regression
    label: Revenue
    description: Revenue prediction model
    training:
      time_limit_seconds: 600
      metric: RSquared

# Shared data paths
data:
  train: datasets/train.csv
  test: datasets/test.csv
```

---

## 8. Core Workflows

### 8.1 Project Initialization Workflow

```
User: mloop init my-project --task binary-classification
  â”‚
  â”œâ”€> Process Start
  â”‚
  â”œâ”€> CLI: Parse and validate command
  â”‚
  â”œâ”€> Core: InitCommand.ExecuteAsync()
  â”‚   â”‚
  â”‚   â”œâ”€> Create project directory structure
  â”‚   â”œâ”€> Initialize .mloop/ directory
  â”‚   â”œâ”€> Generate user files (mloop.yaml, .gitignore, README.md)
  â”‚   â””â”€> Save initial config
  â”‚
  â”œâ”€> CLI: Display success message
  â”‚
  â””â”€> Process Exit (return 0)
```

### 8.2 Training Workflow

```
User: mloop train data.csv --label target --time 600
  â”‚
  â”œâ”€> Process Start
  â”‚
  â”œâ”€> CLI: Parse command and validate inputs
  â”‚
  â”œâ”€> Core: TrainCommand.ExecuteAsync()
  â”‚   â”‚
  â”‚   â”œâ”€> ProjectDiscovery: Find project root (.mloop/)
  â”‚   â”‚
  â”‚   â”œâ”€> ExperimentStore: Generate new experiment ID
  â”‚   â”‚   â””â”€> Atomic update: experiment-index.json
  â”‚   â”‚
  â”‚   â”œâ”€> TrainingEngine: Execute AutoML
  â”‚   â”‚   â”œâ”€> Load and split data
  â”‚   â”‚   â”œâ”€> Run AutoML trials
  â”‚   â”‚   â”œâ”€> Stream progress to CLI (real-time)
  â”‚   â”‚   â””â”€> Select best model
  â”‚   â”‚
  â”‚   â””â”€> ExperimentStore: Save results
  â”‚       â”œâ”€> Create: experiments/exp-XXX/
  â”‚       â”œâ”€> Save: model.zip
  â”‚       â”œâ”€> Save: metadata.json
  â”‚       â”œâ”€> Save: metrics.json
  â”‚       â””â”€> Save: config.json
  â”‚
  â”œâ”€> CLI: Format and display results
  â”‚
  â””â”€> Process Exit (return 0)

# Process exited, all state in filesystem
# Next command starts fresh process
```

### 8.3 Prediction Workflow

```
User: mloop predict models/production/model.zip data.csv
  â”‚
  â”œâ”€> Process Start
  â”‚
  â”œâ”€> CLI: Parse command
  â”‚
  â”œâ”€> Core: PredictCommand.ExecuteAsync()
  â”‚   â”‚
  â”‚   â””â”€> PredictionEngine:
  â”‚       â”œâ”€> Load model.zip
  â”‚       â”œâ”€> Parse input data (CSV/JSON)
  â”‚       â”œâ”€> Execute batch predictions
  â”‚       â””â”€> Generate results
  â”‚
  â”œâ”€> CLI: Output results (console or file)
  â”‚
  â””â”€> Process Exit (return 0)
```

### 8.4 Concurrent Execution Example

```
Terminal 1                     Terminal 2
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ mloop train data.csv
  Process 1234 starts
  â””â”€> exp-001/
      [Training 40%...]
                               $ mloop train data.csv --metric f1
                                 Process 5678 starts
                                 â””â”€> exp-002/
                                     [Training 20%...]
      [Training 80%...]
                                     [Training 60%...]
  âœ… Complete, exit
  Process 1234 exits
                                     [Training 90%...]
                               âœ… Complete, exit
                               Process 5678 exits

Both experiments saved independently
No conflicts, no shared state
```

---

## 9. Configuration Management

### 9.1 Configuration Hierarchy

MLoop merges configuration from multiple sources with the following priority:

1. **CLI Arguments** (Highest Priority)
   - `--label`, `--time`, `--metric`, etc.

2. **mloop.yaml** (Project Level)
   - Project-specific defaults

3. **.mloop/config.json** (Created at init)
   - Initial project settings

4. **Hard-coded Defaults** (Lowest Priority)
   - Built-in default values

**Example Merge:**
```
CLI:           --time 600
mloop.yaml:    time_limit_seconds: 300, metric: f1
config.json:   task: binary-classification
defaults:      test_split: 0.2

Result (single process):
  time_limit_seconds: 600     (from CLI)
  metric: f1                  (from mloop.yaml)
  task: binary-classification (from config.json)
  test_split: 0.2            (from defaults)
```

---

## 10. Git Integration

### 10.1 Version Control Strategy

**Tracked (Committed to Git):**
- `.mloop/config.json` - Project configuration
- `.mloop/registry.json` - Model registry (metadata only)
- `experiments/*/metadata.json` - Experiment metadata
- `experiments/*/metrics.json` - Performance metrics
- `experiments/*/config.json` - Training configuration
- `models/*/metadata.json` - Promoted model metadata
- `mloop.yaml` - User configuration

**Ignored (Not committed):**
- `.mloop/cache/` - Temporary cache
- `experiments/*/model.zip` - Model binaries (large files)
- `experiments/*/training.log` - Detailed logs
- `models/*/model.zip` - Promoted model binaries
- `outputs/` - All output files

### 10.2 Collaboration Workflow

**Developer A (Run Experiment):**
```bash
$ mloop train data.csv --label price
$ git add experiments/exp-005/
$ git commit -m "Experiment 005: LightGBM, Acc=0.92"
$ git push
```

**Developer B (Review Experiment):**
```bash
$ git pull
$ mloop experiment show exp-005  # Read metadata.json, metrics.json
# Model binary can be retrained locally or shared separately
```

---

## 11. Technology Stack

### 11.1 Framework and Runtime

- **.NET 10.0**: Latest LTS version
- **C# 13**: Latest language features
- **Nullable Reference Types**: Enabled
- **Implicit Usings**: Enabled

### 11.2 Core Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| Microsoft.ML | 4.0.0 | ML.NET core framework |
| Microsoft.ML.AutoML | 0.21.1 | AutoML engine |
| System.CommandLine | 2.0.0-beta4 | CLI framework |
| YamlDotNet | 16.2.0 | YAML configuration |
| Spectre.Console | 0.49.1 | Rich CLI UI |

---

## 12. Testing Strategy

### 12.1 Unit Testing

**Scope:**
- Individual components in isolation
- Mock filesystem operations
- Interface-based dependency injection

### 12.2 Integration Testing

**Scope:**
- Multi-component interactions
- Real filesystem operations
- Concurrent execution scenarios

**Example: Concurrent Training Test**
```csharp
[Fact]
public async Task ConcurrentTraining_ShouldGenerateUniqueExperimentIds()
{
    using var tempDir = new TempDirectory();
    await InitProject(tempDir.Path);

    // Run two training jobs concurrently
    var task1 = RunTrainAsync(tempDir.Path, "data1.csv");
    var task2 = RunTrainAsync(tempDir.Path, "data2.csv");

    var results = await Task.WhenAll(task1, task2);

    // Both should succeed with different IDs
    Assert.NotEqual(results[0].ExperimentId, results[1].ExperimentId);
}
```

### 12.3 E2E Testing

**Scope:**
- Full CLI command execution
- Process lifecycle verification
- Multi-terminal concurrent execution

---

## 13. Long-Running Tasks

### 13.1 The Challenge

ML training can take minutes to hours. Users may need to:
- Close their terminal
- Disconnect from remote servers
- Run multiple training jobs
- Monitor progress remotely

### 13.2 Solution: Unix Tools (Not Daemon)

**Why not build a daemon?**
- âŒ Over-engineering for intermittent workloads
- âŒ Additional complexity (process management, ports, etc.)
- âŒ Standard Unix tools already solve this perfectly

**Recommended approaches:**

#### Option 1: nohup (Simple)

```bash
# Start training in background
$ nohup mloop train data.csv --label target --time 3600 > training.log 2>&1 &
[1] 12345

# Close terminal, training continues

# Check progress later
$ tail -f training.log

# Or check experiment files
$ cat experiments/exp-001/metadata.json
```

#### Option 2: screen (Interactive)

```bash
# Start screen session
$ screen -S ml-training

# Run training inside screen
$ mloop train data.csv --label target --time 3600
[Training...]

# Detach: Ctrl+A, then D
[detached from 12345.ml-training]

# Close terminal, training continues

# Reattach later
$ screen -r ml-training
[Training 80%...]
```

#### Option 3: tmux (Advanced)

```bash
# Create tmux session
$ tmux new -s ml-training

# Run training
$ mloop train data.csv --label target --time 3600

# Detach: Ctrl+B, then D

# Reattach later
$ tmux attach -t ml-training
```

### 13.3 Monitoring Progress

**Active monitoring (process running):**
```bash
# Real-time progress in terminal
$ mloop train data.csv --label target
ğŸ” AutoML Progress:
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% | 180s elapsed
```

**Post-execution monitoring:**
```bash
# Check experiment metadata
$ mloop experiment show exp-001

# View training log
$ tail -f experiments/exp-001/training.log

# Check metrics
$ cat experiments/exp-001/metrics.json | jq
```

### 13.4 Future: Optional --detach Flag (Phase 2)

If users really want built-in backgrounding:

```bash
# MLoop handles nohup internally
$ mloop train data.csv --label target --detach
âœ… Training started in background: exp-005
   PID: 12345
   Log: experiments/exp-005/training.log

# Check status
$ mloop experiment show exp-005
Status: in_progress (60% complete)

# Still just a process, not a daemon
# No mloop daemon start/stop/status
```

**Implementation:**
```csharp
if (detach)
{
    // Fork process with nohup
    var process = Process.Start(new ProcessStartInfo
    {
        FileName = "nohup",
        Arguments = $"mloop train {args}",
        RedirectStandardOutput = true,
        RedirectStandardError = true
    });

    Console.WriteLine($"Training started: PID {process.Id}");
    return 0; // Parent exits immediately
}
```

---

## 14. Extensibility System

### 14.1 Overview

**Design Philosophy**: Optional code-based customization while maintaining AutoML simplicity.

MLoop v0.2.0+ includes an **optional extensibility system** that allows users to enhance AutoML with domain knowledge through C# scripts, without sacrificing the simplicity of the base workflow.

**Key Principles:**
- **Completely Optional**: Extensions never required for basic operation
- **Zero-Overhead**: < 1ms performance impact when not used
- **Graceful Degradation**: Extension failures don't break AutoML
- **Type-Safe**: Full C# type system with IDE support
- **Convention-Based**: Automatic discovery via filesystem

**âš ï¸ PRIORITY REVISION (2025-11-09):**

Analysis of Datasets 004-006 revealed **Phase 0 (Preprocessing Scripts) is now P0 CRITICAL**, taking precedence over Phase 1 (Hooks & Metrics).

**Finding**: Current MLoop/FilePrepper handles only **50% of datasets (3/6)**. Critical gaps:
- Multi-file join (Dataset 004)
- Wide-to-Long transformation (Dataset 006)
- Feature engineering (Dataset 005)

**Revised Timeline:**

| Phase | Duration | Target | Priority |
|-------|----------|--------|----------|
| **Phase 0: Preprocessing** | Week 1-2 | Nov 11-22 | **P0 CRITICAL** |
| Phase 1: Hooks & Metrics | Week 3-4 | Nov 25-Dec 6 | P1 HIGH |

### 14.2 Extension Types

#### Phase 0: Preprocessing Scripts (P0 CRITICAL - NEW)

**Purpose**: Data transformation before AutoML training

**Critical Use Cases** (from Dataset Analysis):
- Multi-file operations (join, merge, concat)
- Wide-to-Long transformations (unpivot)
- Feature engineering (computed columns)
- Complex data cleaning beyond FilePrepper

**Interface:**
```csharp
public interface IPreprocessingScript
{
    /// <summary>
    /// Executes preprocessing logic.
    /// Scripts run sequentially: 01_*.cs â†’ 02_*.cs â†’ 03_*.cs
    /// </summary>
    /// <param name="context">Execution context with input/output paths</param>
    /// <returns>Path to output CSV (becomes next script's input)</returns>
    Task<string> ExecuteAsync(PreprocessContext context);
}
```

**Example - Multi-file Join** (Dataset 004):
```csharp
// .mloop/scripts/preprocess/01_join_files.cs
public class JoinMachineAndOrder : IPreprocessingScript
{
    public async Task<string> ExecuteAsync(PreprocessContext ctx)
    {
        var machines = await ctx.Csv.ReadAsync("datasets/raw/machine_info.csv");
        var orders = await ctx.Csv.ReadAsync("datasets/raw/order_info.csv");

        var joined = from m in machines
                     join o in orders on m["item"] equals o["ì¤‘ì‚°ë„ë©´"]
                     select new Dictionary<string, string>
                     {
                         ["ì„¤ë¹„ëª…"] = m["ì„¤ë¹„ëª…"],
                         ["item"] = m["item"],
                         ["ì¬ê³ "] = o["ì¬ê³ "],
                         ["ìƒì‚°í•„ìš”ëŸ‰"] = o["ìƒì‚°í•„ìš”ëŸ‰"]
                     };

        return await ctx.Csv.WriteAsync(
            Path.Combine(ctx.OutputDirectory, "01_joined.csv"),
            joined.ToList());
    }
}
```

**Example - Wide-to-Long** (Dataset 006):
```csharp
// .mloop/scripts/preprocess/01_unpivot_shipments.cs
public class UnpivotShipments : IPreprocessingScript
{
    public async Task<string> ExecuteAsync(PreprocessContext ctx)
    {
        var data = await ctx.Csv.ReadAsync(ctx.InputPath);
        var longData = new List<Dictionary<string, string>>();

        foreach (var row in data)
        {
            for (int i = 1; i <= 10; i++)
            {
                var dateCol = $"{i}ì°¨ ì¶œê³ ë‚ ì§œ";
                var qtyCol = $"{i}ì°¨ ì¶œê³ ëŸ‰";

                if (!string.IsNullOrEmpty(row[dateCol]))
                {
                    longData.Add(new Dictionary<string, string>
                    {
                        ["ì‘ì—…ì§€ì‹œë²ˆí˜¸"] = row["ì‘ì—…ì§€ì‹œë²ˆí˜¸"],
                        ["ì¶œê³ ì°¨ìˆ˜"] = i.ToString(),
                        ["ì¶œê³ ë‚ ì§œ"] = row[dateCol],
                        ["ì¶œê³ ëŸ‰"] = row[qtyCol]
                    });
                }
            }
        }

        return await ctx.Csv.WriteAsync(
            Path.Combine(ctx.OutputDirectory, "01_unpivoted.csv"),
            longData);
    }
}
```

**Execution Flow:**
```
User: mloop train datasets/raw.csv --label "quantity"
  â†“
1. CLI detects .mloop/scripts/preprocess/*.cs
  â†“
2. PreprocessingEngine executes sequentially:
   - 01_join.cs: raw.csv â†’ .mloop/temp/01_joined.csv
   - 02_features.cs: 01_joined.csv â†’ .mloop/temp/02_features.csv
   - 03_datetime.cs: 02_features.csv â†’ datasets/train.csv
  â†“
3. TrainingEngine trains on final output: datasets/train.csv
```

**PreprocessContext:**
```csharp
public class PreprocessContext
{
    public string InputPath { get; set; }          // Input CSV path
    public string OutputDirectory { get; set; }     // Temp directory
    public string ProjectRoot { get; set; }         // Project root
    public CsvHelper Csv { get; set; }              // CSV helper
    public IFilePrepper FilePrepper { get; set; }   // FilePrepper integration
    public ILogger Logger { get; set; }             // Logger
}
```

**CLI Commands:**
```bash
# Auto-preprocessing (recommended)
mloop train datasets/raw.csv --label "quantity" --time 120
# â†’ Auto-detects scripts â†’ Runs preprocessing â†’ Trains

# Manual preprocessing (debugging)
mloop preprocess --input datasets/raw.csv --output datasets/train.csv

# Validate scripts
mloop validate --scripts
```

#### Phase 1: Hooks (Lifecycle Extensions)

**Purpose**: Execute custom logic at specific pipeline points

```
mloop train data.csv
    â†“
[pre-train hook]  â† Data validation, preprocessing checks
    â†“
AutoML Training
    â†“
[post-train hook] â† Model validation, deployment, logging
    â†“
Save Results
```

**Hook Points:**
- `pre-train`: Before AutoML training (data validation)
- `post-train`: After AutoML training (model validation, deployment)
- `pre-predict`: Before batch prediction (input validation)
- `post-evaluate`: After model evaluation (reporting, analysis)

**Use Cases:**
- Data quality validation
- MLflow/W&B integration
- Model performance gates
- Automated deployment triggers

#### Custom Metrics (Business-Aligned Evaluation)

**Purpose**: Define business-specific optimization objectives for AutoML

**Standard Metrics** (Built-in):
```bash
mloop train data.csv --label target --metric accuracy
# Uses: Accuracy, F1, AUC, Precision, Recall
```

**Custom Business Metrics**:
```bash
mloop train data.csv --label target --metric profit-metric.cs
# AutoML optimizes for: Expected Profit, Churn Cost, ROI, etc.
```

### 14.3 Architecture Integration

#### Directory Structure

```
.mloop/
â”œâ”€â”€ scripts/                     # Extension scripts (Phase 1+)
â”‚   â”œâ”€â”€ hooks/                   # Lifecycle hooks
â”‚   â”‚   â”œâ”€â”€ pre-train.cs
â”‚   â”‚   â”œâ”€â”€ post-train.cs
â”‚   â”‚   â”œâ”€â”€ pre-predict.cs
â”‚   â”‚   â””â”€â”€ post-evaluate.cs
â”‚   â””â”€â”€ metrics/                 # Custom metrics
â”‚       â”œâ”€â”€ profit-metric.cs
â”‚       â””â”€â”€ churn-cost.cs
â”œâ”€â”€ .cache/                      # Compiled DLLs (auto-generated)
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ hooks.pre-train.dll
â”‚       â””â”€â”€ metrics.profit-metric.dll
â””â”€â”€ config.json
```

#### Component Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLoop.Extensibility (New NuGet Package)            â”‚
â”‚  â”œâ”€ Interfaces (IMLoopHook, IMLoopMetric)          â”‚
â”‚  â”œâ”€ Context Classes (HookContext, MetricContext)   â”‚
â”‚  â””â”€ Result Classes (HookResult)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLoop.Core (Enhanced)                              â”‚
â”‚  â”œâ”€ Scripting/                                      â”‚
â”‚  â”‚  â”œâ”€ ScriptLoader.cs (Hybrid compilation)        â”‚
â”‚  â”‚  â”œâ”€ ScriptDiscovery.cs (Auto-discovery)         â”‚
â”‚  â”‚  â””â”€ ScriptCompiler.cs (Roslyn wrapper)          â”‚
â”‚  â””â”€ AutoML/                                         â”‚
â”‚     â””â”€ TrainingEngine.cs (Hook integration)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 14.4 Extension Discovery Flow

```
1. User runs: mloop train data.csv --label target
       â†“
2. Extension Check:
   - .mloop/scripts/ exists? â†’ Yes/No
   - Overhead if No: < 1ms (directory check only)
       â†“
3. If Yes, Script Discovery:
   - Scan .mloop/scripts/hooks/*.cs
   - Scan .mloop/scripts/metrics/*.cs
       â†“
4. Hybrid Compilation:
   - Check .cache/*.dll (cached?)
   - If cached & up-to-date â†’ Load DLL (fast: ~50ms)
   - If not â†’ Compile .cs â†’ Cache DLL (first time: ~500ms)
       â†“
5. Validation:
   - Implements required interface?
   - No compilation errors?
   - On failure â†’ Warning + Continue with AutoML
       â†“
6. Execution:
   - Hook: Execute at lifecycle point
   - Metric: Pass to AutoML optimizer
       â†“
7. AutoML Training (always runs)
```

### 14.5 Hybrid Compilation Strategy

**Challenge**: Balance flexibility (runtime .cs loading) with performance (pre-compiled DLLs)

**Solution**: Hybrid approach combining Roslyn scripting with DLL caching

```csharp
// ScriptLoader implementation
public async Task<T?> LoadScriptAsync<T>(string scriptPath)
{
    var dllPath = GetCachedDllPath(scriptPath);

    // Fast path: Load cached DLL if up-to-date
    if (IsCacheValid(scriptPath, dllPath))
    {
        return LoadFromDll<T>(dllPath);  // ~50ms
    }

    // Slow path: Compile .cs â†’ Cache DLL
    var assembly = await CompileScriptAsync(scriptPath);  // ~500ms
    await SaveAssemblyAsync(assembly, dllPath);

    return LoadFromDll<T>(dllPath);
}

private bool IsCacheValid(string scriptPath, string dllPath)
{
    return File.Exists(dllPath) &&
           File.GetLastWriteTime(dllPath) >= File.GetLastWriteTime(scriptPath);
}
```

**Benefits:**
- âœ… Development: Edit .cs files with full IDE support (IntelliSense, debugging)
- âœ… First Run: Automatic compilation and caching
- âœ… Subsequent Runs: Fast DLL loading
- âœ… Deployment: Pre-compiled DLLs can be included

**Performance:**
```
Extension Check (no scripts):  < 1ms
First Run (compile + cache):   ~500ms
Cached Runs (load DLL):        ~50ms
AutoML Training:               ~300s (unchanged)
```

### 14.6 Graceful Degradation

**Design Goal**: Extension failures never break AutoML

**Error Handling Strategy:**

```csharp
public async Task<IEnumerable<IMLoopHook>> DiscoverHooksAsync()
{
    var hooks = new List<IMLoopHook>();

    if (!Directory.Exists(".mloop/scripts/hooks"))
    {
        // No hooks directory â†’ No error, empty list
        return hooks;
    }

    foreach (var scriptFile in Directory.GetFiles(scriptsDir, "*.cs"))
    {
        try
        {
            var hook = await _scriptLoader.LoadScriptAsync<IMLoopHook>(scriptFile);
            if (hook != null)
                hooks.Add(hook);
        }
        catch (CompilationException ex)
        {
            _logger.Warning($"âš ï¸  Compilation failed: {scriptFile}");
            _logger.Warning(ex.Message);
            // Continue with other scripts
        }
        catch (Exception ex)
        {
            _logger.Error($"âŒ Unexpected error: {ex.Message}");
            // Continue with other scripts
        }
    }

    return hooks;  // Return whatever loaded successfully
}
```

**User Experience:**
```bash
$ mloop train data.csv --label target

ğŸ” Discovering extensions...
   âš ï¸  Compilation failed: pre-train.cs
       Line 15: Syntax error
   âœ… Loaded hook: post-train.cs (MLflow Logging)

âš ï¸  Warning: Some extensions failed to load
    Continuing with AutoML...

ğŸš€ Training started (AutoML only)
âœ… Training completed
```

### 14.7 Multi-Process Compatibility

**Extensions work seamlessly with multi-process model:**

```
Terminal 1                     Terminal 2
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ mloop train data.csv         $ mloop train data.csv
  Process 1234 starts            Process 5678 starts

  Load extensions (in-process)   Load extensions (in-process)
  â”œâ”€ Compile/load hooks          â”œâ”€ Load from cache (shared .dll)
  â””â”€ Execute hooks               â””â”€ Execute hooks

  AutoML training                AutoML training
  [exp-001]                      [exp-002]

  Process 1234 exits             Process 5678 exits
```

**Key Points:**
- Each process loads extensions independently
- DLL cache is shared (filesystem-based)
- No inter-process communication needed
- Natural isolation via process boundaries

### 14.8 Example: Data Validation Hook

```csharp
// .mloop/scripts/hooks/pre-train.cs
using MLoop.Extensibility;

public class DataValidationHook : IMLoopHook
{
    public string Name => "Data Quality Check";

    public async Task<HookResult> ExecuteAsync(HookContext ctx)
    {
        var preview = ctx.DataView.Preview(maxRows: 1000);
        var rowCount = preview.RowView.Length;

        // Minimum row check
        if (rowCount < 100)
        {
            return HookResult.Abort(
                $"Insufficient data: {rowCount} < 100 rows");
        }

        // Class imbalance check
        var labelCol = ctx.Metadata["LabelColumn"] as string;
        var distribution = AnalyzeClassBalance(ctx.DataView, labelCol);

        if (distribution.ImbalanceRatio > 20)
        {
            ctx.Logger.Warning(
                $"âš ï¸  Severe class imbalance: {distribution.ImbalanceRatio:F1}:1");
        }

        ctx.Logger.Info($"âœ… Validation passed: {rowCount} rows");
        return HookResult.Continue();
    }
}
```

**Usage:**
```bash
$ mloop train data.csv --label target

ğŸ“Š Executing hook: Data Quality Check
   âœ… Validation passed: 1,234 rows

ğŸš€ AutoML training...
```

### 14.9 Example: Custom Business Metric

```csharp
// .mloop/scripts/metrics/profit-metric.cs
using MLoop.Extensibility;

public class ProfitMetric : IMLoopMetric
{
    public string Name => "Expected Profit";
    public bool HigherIsBetter => true;

    private const double PROFIT_PER_TP = 100.0;
    private const double LOSS_PER_FP = -50.0;

    public async Task<double> CalculateAsync(MetricContext ctx)
    {
        var metrics = ctx.MLContext.BinaryClassification
            .Evaluate(ctx.Predictions);

        return (metrics.PositiveRecall * PROFIT_PER_TP) +
               (metrics.FalsePositiveRate * LOSS_PER_FP);
    }
}
```

**Usage:**
```bash
$ mloop train data.csv --label target --metric profit-metric.cs

ğŸ¯ Optimization metric: Expected Profit (higher is better)

â±ï¸  AutoML searching...
   Trial 1: LightGbm â†’ $45.32
   Trial 2: FastTree â†’ $48.91 â­
   Trial 3: SdcaLogistic â†’ $43.17

âœ… Best model: FastTree ($48.91 expected profit)
```

### 14.10 CLI Commands

```bash
# Create new extension
mloop new hook --name DataValidation --type pre-train
mloop new metric --name ProfitMetric

# Validate extension
mloop validate .mloop/scripts/hooks/pre-train.cs
# âœ… Compilation successful
# âœ… Implements IMLoopHook

# List extensions
mloop extensions list
# Hooks:
#   âœ… pre-train.cs (Data Validation)
#   âœ… post-train.cs (MLflow Logging)
# Metrics:
#   âœ… profit-metric.cs (Expected Profit)

# Clean cache
mloop extensions clean
# Removed 5 cached DLLs
```

### 14.11 Backward Compatibility

**Guarantee**: All existing workflows continue to work unchanged

```bash
# âœ… Still works perfectly (no extensions)
$ mloop train data.csv --label target

# âœ… Extensions auto-discovered if .mloop/scripts/ exists
$ mloop train data.csv --label target

# âœ… Force disable extensions
$ mloop train data.csv --label target --no-extensions
```

**Version Policy:**
- v0.1.x: Pure AutoML (no extensions)
- v0.2.x: Hooks & Metrics (opt-in, zero breaking changes)
- v0.3.x: Transforms & Pipelines (opt-in, compatible with v0.2.x)

### 14.12 Implementation Roadmap

**Timeline** (Revised 2025-11-09):

| Phase | Duration | Target | Priority | Status |
|-------|----------|--------|----------|--------|
| **Phase 0.1** | Week 1 | Nov 11-15 | **P0 CRITICAL** | ğŸ“‹ Planned |
| **Phase 0.2** | Week 2 | Nov 18-22 | **P0 CRITICAL** | ğŸ“‹ Planned |
| **Phase 1.1** | Week 3 | Nov 25-29 | P1 HIGH | ğŸ“‹ Planned |
| **Phase 1.2** | Week 4 | Dec 2-6 | P1 HIGH | ğŸ“‹ Planned |
| **Release** | - | Dec 6 | - | ğŸ¯ Target |

**Phase 0: Preprocessing Scripts** (P0 CRITICAL - Weeks 1-2):
- **Week 1**: Core infrastructure (IPreprocessingScript, ScriptCompiler, PreprocessingEngine)
- **Week 2**: CLI integration (`mloop preprocess`, auto-run in `mloop train`)
- **Goal**: Achieve 100% dataset coverage (6/6 datasets)

**Phase 1: Hooks & Metrics** (P1 HIGH - Weeks 3-4):
- **Week 3**: Hooks infrastructure (IMLoopHook, HookContext, TrainingEngine integration)
- **Week 4**: Custom metrics (IMLoopMetric, AutoML integration)
- **Goal**: Enable business-aligned optimization

**Success Criteria**:
- [ ] Dataset coverage: 100% (6/6 datasets trainable)
- [ ] Backward compatibility: 100% (no breaking changes)
- [ ] Extension overhead: < 1ms when not used
- [ ] Test coverage: >90% for new code
- [ ] Documentation complete with examples

---

## 15. Future Extensibility

### 15.1 Why NOT Background Service (Phase 2)

**Original concern**: "Long training blocks CLI"

**Reality**:
- âœ… Unix tools (nohup, screen, tmux) solve this perfectly
- âœ… Users already familiar with these tools
- âœ… No need to reinvent process management
- âŒ Background daemon adds complexity
- âŒ MLoop workloads are intermittent, not continuous

**Decision**: Stick with multi-process model indefinitely

**If absolutely needed:** Add `--detach` flag (Phase 2), which internally uses `nohup`, not a daemon

### 15.2 Advanced Extensions (Phase 2)

**Potential additions beyond Hooks & Metrics:**
- Custom Transforms (feature engineering scripts)
- Full Pipelines (complete workflow control)
- Dependency management (NuGet references in scripts)

**Note**: These will build on Phase 1 infrastructure (ScriptLoader, discovery, etc.)

### 15.3 Plugin System (Future)

**Potential Plugin Types:**
- Custom Trainers
- Data Loaders
- Storage Providers
- Metric Calculators

**Each plugin runs in-process:**
```csharp
public interface IPlugin
{
    string Name { get; }
    string Version { get; }
    void Initialize(IServiceProvider services);
}

// Loaded per-process, no shared state
var plugins = PluginLoader.Load(".mloop/plugins/");
foreach (var plugin in plugins)
{
    plugin.Initialize(services);
}
```

### 15.4 Remote Storage Support (Future)

**Filesystem abstraction enables remote storage:**

```csharp
public interface IStorageProvider
{
    Task<Stream> ReadAsync(string path);
    Task WriteAsync(string path, Stream content);
}

// Each process connects independently
var storage = config.StorageProvider switch
{
    "local" => new LocalStorageProvider(),
    "azure-blob" => new AzureBlobStorageProvider(),
    _ => throw new NotSupportedException()
};
```

**Multi-process still works:**
- Each process instance connects to storage
- No shared in-memory state
- Filesystem-like operations over network

---

## 15. Performance and Constraints

### 15.1 Target Scale

**Suitable:**
- Dataset size: < 1GB
- Training time: < 1 hour
- Concurrent experiments: Unlimited (filesystem isolated)
- Concurrent processes: Limited by system resources

**Process overhead:**
- Startup time: < 100ms
- Memory per process: ~50-200MB (ML.NET models)
- Acceptable for intermittent workloads

### 15.2 Filesystem Considerations

**Multi-process file locking:**
```csharp
// Atomic ID generation with retry
public async Task<string> GenerateExperimentIdAsync()
{
    for (int retry = 0; retry < 3; retry++)
    {
        try
        {
            // OS-level file locking
            using var fs = new FileStream(
                indexPath,
                FileMode.Open,
                FileAccess.ReadWrite,
                FileShare.None); // Exclusive lock

            var index = await ReadIndexAsync(fs);
            index.NextId++;
            await WriteIndexAsync(fs, index);
            return $"exp-{index.NextId:D3}";
        }
        catch (IOException)
        {
            // Another process has lock, retry
            await Task.Delay(100);
        }
    }
    throw new ConcurrencyException();
}
```

---

## 16. Security Considerations

### 16.1 Process Isolation

**Advantages:**
- âœ… Each command runs in separate process
- âœ… No shared memory between executions
- âœ… OS-level security boundaries
- âœ… Failed process doesn't affect others

### 16.2 Data Security

- Sensitive data in `.gitignore`
- Model encryption (future, if needed)
- No network exposure (except `mloop serve`)

---

## 17. Conclusion

MLoop's **multi-process casual design** perfectly matches its usage pattern and philosophy:

### 17.1 Core Principles

1. **Simplicity**: Each command = Independent process
2. **Transparency**: All state in filesystem, not daemon memory
3. **Isolation**: Natural process and filesystem boundaries
4. **Practicality**: Unix tools handle long-running tasks
5. **No Over-Engineering**: No daemon for intermittent workloads

### 17.2 Key Decisions

| Decision | Rationale |
|----------|-----------|
| **Multi-Process** | ML workloads are intermittent (train â†’ exit) |
| **No Daemon** | Unix tools (nohup, screen) solve long-running needs |
| **Filesystem State** | Enables natural isolation and Git integration |
| **In-Process Core** | Simpler than IPC, adequate for single-command execution |
| **Exception: serve** | Only API serving needs persistent process |

### 17.3 Future-Proof

- âœ… Plugin system: In-process loading
- âœ… Remote storage: Per-process connections
- âœ… Optional --detach: Internal nohup, not daemon
- âŒ Background service: Rejected as over-engineering

---

## Appendix A: Quick Reference

### A.1 Process Lifecycle

```
Command Invocation
    â†“
Process Start
    â†“
Load Configuration (from filesystem)
    â†“
Execute Core Logic
    â†“
Save Results (to filesystem)
    â†“
Process Exit
    â†“
No residual state in memory
```

### A.2 Key Commands (Phase 1)

| Command | Process Behavior |
|---------|------------------|
| `mloop init` | Start â†’ Create structure â†’ Exit |
| `mloop train` | Start â†’ Train â†’ Save â†’ Exit |
| `mloop predict` | Start â†’ Load â†’ Predict â†’ Exit |
| `mloop evaluate` | Start â†’ Load â†’ Evaluate â†’ Exit |
| `mloop serve` | Start â†’ Listen â†’ (User Ctrl+C) â†’ Exit |

### A.3 Concurrent Execution Patterns

```bash
# Same project, different experiments
Terminal 1: mloop train data.csv --time 300  â†’ exp-001
Terminal 2: mloop train data.csv --time 600  â†’ exp-002

# Different projects, any command
Terminal 1: cd project-A && mloop train ...
Terminal 2: cd project-B && mloop train ...

# All work perfectly, no conflicts
```

---

**Version**: 1.2.0
**Last Updated**: 2026-01-12
**Status**: Living Document
**Process Model**: Multi-Process Casual
**Multi-Model Support**: Yes (v0.2.0+)
**Project Count**: 6 (Core, CLI, API, Extensibility, DataStore, Ops)
