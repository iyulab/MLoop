# MLoop Architecture Documentation

## Table of Contents

1. [Overview](#1-overview)
2. [Architectural Principles](#2-architectural-principles)
3. [Process Model](#3-process-model)
4. [System Architecture](#4-system-architecture)
5. [Layer Design](#5-layer-design)
6. [Project Structure](#6-project-structure)
7. [Data Models](#7-data-models)
8. [Core Workflows](#8-core-workflows)
9. [Configuration Management](#9-configuration-management)
10. [Git Integration](#10-git-integration)
11. [Technology Stack](#11-technology-stack)
12. [Testing Strategy](#12-testing-strategy)
13. [Long-Running Tasks](#13-long-running-tasks)
14. [Future Extensibility](#14-future-extensibility)

---

## 1. Overview

MLoop is a lightweight MLOps platform built on ML.NET, designed with a **filesystem-first** and **multi-process casual** approach that emphasizes simplicity, transparency, and Git compatibility.

### 1.1 Core Mission

**"Clean Data In, Trained Model Out - That's It."**

MLoop fills the gap left by Microsoft's discontinued ML.NET CLI, providing .NET developers with a modern, production-ready tool for the complete ML lifecycle.

### 1.2 Design Principles

- **Filesystem-First**: All state managed as files, perfect Git integration
- **Multi-Process Casual**: Each command runs independently, no daemon required
- **Zero Configuration**: Usable immediately with minimal setup
- **Layer Separation**: Clear separation between CLI, Core, and Storage
- **Lightweight**: Independent operation without complex dependencies
- **AutoML-Driven**: Automatic model selection over manual tuning

### 1.3 Target Use Cases

**âœ… Suitable For:**
- Medium datasets (< 1GB)
- Standard ML problems (classification, regression)
- Fast prototyping and iteration
- .NET ecosystem projects
- Intermittent ML workloads (train â†’ exit, predict â†’ exit)

**âŒ Not Suitable For:**
- Complex feature engineering needs
- State-of-the-art performance requirements
- Large-scale datasets (> 10GB)
- Real-time learning/retraining
- Always-on service requirements

---

## 2. Architectural Principles

### 2.1 SOLID Principles

- **Single Responsibility**: Each component has one reason to change
- **Open/Closed**: Open for extension, closed for modification
- **Liskov Substitution**: Derived classes substitutable for base classes
- **Interface Segregation**: No dependencies on unused interfaces
- **Dependency Inversion**: Depend on abstractions, not concretions

### 2.2 Design Philosophy

#### Lightweight First
- User handles data preprocessing
- Accept clean, preprocessed data only
- Focus on AutoML capabilities
- Minimal dependency footprint
- **No daemon or background service management**

#### Usability Over Everything
- AutoML-centric workflow
- Speed over precision for prototyping
- 3-step workflow: `init â†’ train â†’ predict`
- Sensible defaults for everything
- **Simple process lifecycle: Start â†’ Execute â†’ Exit**

#### Filesystem-First MLOps
- All state persisted as files
- Git-friendly structure
- No external databases or services
- Human-readable formats (JSON, YAML)
- **Natural multi-process isolation via filesystem**

---

## 3. Process Model

### 3.1 Multi-Process Casual Design

**Core Concept**: Each MLoop command runs as an **independent process** that exits when complete.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Traditional Daemon Model (NOT MLoop)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  $ mloop daemon start      â† Start service     â”‚
â”‚  $ mloop train data.csv    â† Submit to daemon  â”‚
â”‚  $ mloop daemon stop       â† Stop service      â”‚
â”‚                                                 â”‚
â”‚  âŒ Complex: Port management, PID files, etc.  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLoop Multi-Process Model (Phase 1)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  $ mloop train data.csv    â† Start process     â”‚
â”‚      [Training... 5 min]                        â”‚
â”‚      âœ… Complete, exit                          â”‚
â”‚                                                 â”‚
â”‚  $ mloop predict model.zip data.csv             â”‚
â”‚      [Predicting... 10 sec]                     â”‚
â”‚      âœ… Complete, exit                          â”‚
â”‚                                                 â”‚
â”‚  âœ… Simple: No daemon, no management            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Why Multi-Process Casual?

#### Perfect for MLoop's Usage Pattern

**MLoop workloads are intermittent, not continuous:**
```bash
# Typical workflow
$ mloop train data.csv --label target
  â†’ Train for 10 minutes â†’ Exit

$ mloop evaluate exp-001/model.zip test.csv
  â†’ Evaluate for 30 seconds â†’ Exit

$ mloop predict exp-001/model.zip new-data.csv
  â†’ Predict for 10 seconds â†’ Exit
```

**vs Docker (continuous service):**
```bash
$ docker run -d my-service  # Daemon mode
$ docker ps                 # Persistent service
$ docker stop my-service    # Explicit stop
```

MLoop doesn't need to stay running between operations.

#### Advantages

| Aspect | Multi-Process | Background Daemon |
|--------|---------------|-------------------|
| **Simplicity** | â­â­â­â­â­ Minimal | â­â­ Complex |
| **Management** | âœ… None required | âŒ start/stop/status/restart |
| **Isolation** | âœ… Perfect (per-process) | âš ï¸ Shared daemon |
| **Concurrent Jobs** | âœ… Natural support | âš ï¸ Requires job queue |
| **Debugging** | âœ… Direct terminal output | âŒ Log file inspection |
| **Port Conflicts** | âœ… N/A | âŒ Possible |
| **Process Cleanup** | âœ… OS handles | âŒ Manual management |
| **Usage Pattern Fit** | âœ… Perfect match | âŒ Over-engineering |

#### Disadvantages (and Mitigation)

**Concern**: "What about long-running training jobs?"

**Solution**: Use standard Unix tools (see [Section 13](#13-long-running-tasks))
```bash
# Option 1: nohup
$ nohup mloop train data.csv --label target --time 3600 &

# Option 2: screen/tmux
$ screen -S ml-training
$ mloop train data.csv --label target --time 3600
# Ctrl+A, D to detach
```

### 3.3 Exception: mloop serve

The `mloop serve` command is the **only exception** that maintains a server process:

```bash
$ mloop serve models/production/model.zip --port 5000
ğŸš€ MLoop API Server
   Listening on: http://localhost:5000
   Swagger UI: http://localhost:5000/swagger

   Press Ctrl+C to stop

# Server process stays alive
# Standard web server pattern
# User explicitly controls lifecycle
```

**Why this is different:**
- API serving requires persistent HTTP listener
- User explicitly requests long-running service
- Standard web server behavior (like `dotnet run`)
- Simple lifecycle: Start with command, stop with Ctrl+C

**No daemon management needed:**
- No background service
- No `mloop serve start/stop/status`
- Just run in terminal or use `nohup` if needed

### 3.4 Concurrent Execution

**Natural isolation via filesystem:**

```bash
# Terminal 1: Project A
$ cd ~/projects/sentiment-analyzer
$ mloop train data.csv --label sentiment
  â†’ experiments/exp-001/

# Terminal 2: Project B (concurrent!)
$ cd ~/projects/price-predictor
$ mloop train data.csv --label price
  â†’ experiments/exp-001/

# No conflicts!
# Each project has independent .mloop/ directory
# Filesystem provides natural isolation
```

**Same project, different experiments:**
```bash
# Terminal 1
$ mloop train data.csv --label target --time 300
  â†’ experiments/exp-001/

# Terminal 2 (while #1 is running)
$ mloop train data.csv --label target --time 600 --metric f1
  â†’ experiments/exp-002/

# Works perfectly!
# Each gets unique experiment ID
# No shared state, no locks needed
```

---

## 4. System Architecture

### 4.1 Layered Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Interface Layer (CLI)                      â”‚
â”‚                                                              â”‚
â”‚  Each command execution = New process instance              â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Command    â”‚  â”‚  Validation  â”‚  â”‚   Progress   â”‚      â”‚
â”‚  â”‚   Parsing    â”‚  â”‚   & Error    â”‚  â”‚   Reporter   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ In-Process Method Calls
                         â”‚ (No IPC, No gRPC)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core Engine Layer                         â”‚
â”‚                                                              â”‚
â”‚  Instantiated per command execution                          â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Training   â”‚  â”‚  Prediction  â”‚  â”‚  Evaluation  â”‚      â”‚
â”‚  â”‚   Engine     â”‚  â”‚   Engine     â”‚  â”‚   Engine     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   AutoML     â”‚  â”‚    Model     â”‚  â”‚  Experiment  â”‚      â”‚
â”‚  â”‚   Runner     â”‚  â”‚   Registry   â”‚  â”‚    Store     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚         FileSystem Manager                       â”‚        â”‚
â”‚  â”‚         (Storage Abstraction)                    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ File I/O Operations
                         â”‚ (Stateless, thread-safe)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Storage Layer                             â”‚
â”‚                                                              â”‚
â”‚  Filesystem Structure (Provides isolation)                   â”‚
â”‚  â”œâ”€â”€ .mloop/          (Project metadata)                    â”‚
â”‚  â”œâ”€â”€ experiments/     (Training results)                    â”‚
â”‚  â”œâ”€â”€ models/          (Promoted models)                     â”‚
â”‚  â”œâ”€â”€ data/            (User data)                           â”‚
â”‚  â””â”€â”€ outputs/         (Predictions, reports)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Process Lifecycle:
1. User runs command â†’ New process starts
2. CLI parses â†’ Core executes â†’ Storage persists
3. Command completes â†’ Process exits
4. No background service, no daemon
```

### 4.2 Process Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  mloop train data.csv --label target             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Process Start â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Load Config   â”‚
         â”‚  Find Project  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Execute Core  â”‚
         â”‚  (Training)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Save Results  â”‚
         â”‚  to Filesystem â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Process Exit   â”‚
         â”‚  (Return code) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

No state preserved between executions
Next command starts fresh process
```

### 4.3 State Management

**All state lives in filesystem, not in memory:**

```csharp
// âŒ ANTI-PATTERN: In-memory state (daemon model)
public class MLoopDaemon
{
    private Dictionary<string, TrainingJob> _activeJobs;
    private ModelCache _modelCache;
    // State lost on process exit!
}

// âœ… MLoop Pattern: Filesystem state
public class TrainingEngine
{
    public async Task<TrainingResult> TrainAsync(TrainingConfig config)
    {
        // 1. Read config from filesystem
        var projectConfig = await _fileSystem.LoadConfigAsync();

        // 2. Execute training
        var result = await _autoML.TrainAsync(config);

        // 3. Persist everything to filesystem
        await _experimentStore.SaveAsync(result);

        // 4. Process exits, state preserved in files
        return result;
    }
}
```

**Benefits:**
- âœ… No state synchronization between processes
- âœ… Crash-safe (filesystem is durable)
- âœ… Easy to inspect state (`cat experiments/exp-001/metadata.json`)
- âœ… Natural versioning with Git

---

## 5. Layer Design

### 5.1 User Interface Layer (CLI)

**Responsibilities:**
- Parse and validate user commands
- Instantiate Core Engine components
- Provide real-time user feedback (progress bars, logs)
- Format output (tables, JSON, text)
- Exit with appropriate return code

**Key Components:**
- **Command Parser**: System.CommandLine for parsing
- **Validator**: Input validation and error handling
- **Progress Reporter**: Spectre.Console for visual feedback
- **Output Formatter**: Multiple output format support

**Design Guidelines:**
- Keep layer thin (no business logic)
- Direct method calls to Core Engine (no IPC)
- Focus on user experience optimization
- Synchronous execution (await completion)

**Example Implementation:**
```csharp
public class TrainCommand : Command
{
    public TrainCommand() : base("train", "Train a model using AutoML")
    {
        var dataFileArg = new Argument<string>("data-file");
        var labelOption = new Option<string>("--label");

        AddArgument(dataFileArg);
        AddOption(labelOption);

        this.SetHandler(ExecuteAsync, dataFileArg, labelOption);
    }

    private async Task<int> ExecuteAsync(string dataFile, string label)
    {
        try
        {
            // 1. Validate inputs
            if (!File.Exists(dataFile))
                return Error("Data file not found");

            // 2. Find project root
            var projectRoot = ProjectDiscovery.FindRoot();

            // 3. Instantiate Core Engine (in-process)
            var engine = new TrainingEngine(projectRoot);

            // 4. Execute training
            var result = await engine.TrainAsync(new TrainingConfig
            {
                DataFile = dataFile,
                LabelColumn = label
            });

            // 5. Display results
            DisplayResults(result);

            // 6. Exit with success
            return 0;
        }
        catch (Exception ex)
        {
            Error(ex.Message);
            return 1;
        }
        // Process exits after return
    }
}
```

### 5.2 Core Engine Layer

**Responsibilities:**
- All ML-related business logic
- Filesystem state management
- ML.NET and AutoML orchestration
- Experiment tracking and model registry

**Key Components:**

#### Training Engine
```csharp
namespace MLoop.Core.AutoML;

public interface ITrainingEngine
{
    Task<TrainingResult> TrainAsync(
        TrainingConfig config,
        IProgress<TrainingProgress> progress,
        CancellationToken cancellationToken);
}

public class TrainingEngine : ITrainingEngine
{
    private readonly IFileSystemManager _fileSystem;
    private readonly IAutoMLRunner _autoML;
    private readonly IExperimentStore _experiments;

    public async Task<TrainingResult> TrainAsync(
        TrainingConfig config,
        IProgress<TrainingProgress> progress,
        CancellationToken cancellationToken)
    {
        // 1. Generate experiment ID
        var experimentId = await _experiments.GenerateIdAsync();

        // 2. Run AutoML
        var mlResult = await _autoML.RunAsync(config, progress, cancellationToken);

        // 3. Save results to filesystem
        await _experiments.SaveAsync(experimentId, mlResult);

        // 4. Return (process will exit)
        return new TrainingResult
        {
            ExperimentId = experimentId,
            BestTrainer = mlResult.BestTrainer,
            Metrics = mlResult.Metrics
        };
    }
}
```

#### Prediction Engine
```csharp
namespace MLoop.Core.Models;

public interface IPredictionEngine
{
    Task<PredictionResult> PredictAsync(
        string modelPath,
        IDataSource dataSource,
        CancellationToken cancellationToken);
}
```

#### Evaluation Engine
```csharp
namespace MLoop.Core.Evaluation;

public interface IEvaluator
{
    Task<EvaluationResult> EvaluateAsync(
        string modelPath,
        IDataSource testData,
        CancellationToken cancellationToken);
}
```

**Thread Safety:**
- Each process instance is single-threaded for commands
- No shared state between processes
- Filesystem operations use OS-level locking
- No need for distributed locks or semaphores

### 5.3 Storage Layer (Filesystem)

**Responsibilities:**
- Persist all project data as files
- Provide Git-friendly structure
- Use human-readable formats (JSON, YAML)
- Enable natural multi-process isolation

**Thread-Safe Operations:**
```csharp
public class FileSystemManager : IFileSystemManager
{
    // Atomic operations via OS
    public async Task<string> GenerateExperimentIdAsync()
    {
        // Read-Modify-Write with retry
        for (int retry = 0; retry < 3; retry++)
        {
            try
            {
                var index = await ReadIndexAsync();
                var newId = $"exp-{index.NextId:D3}";
                index.NextId++;
                await WriteIndexAsync(index);
                return newId;
            }
            catch (IOException)
            {
                // Another process modified file, retry
                await Task.Delay(100);
            }
        }
        throw new ConcurrencyException("Failed to generate ID");
    }
}
```

---

## 6. Project Structure

### 6.1 Development Project Structure

```
MLoop/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ MLoop.sln                        # .NET 9 Solution
â”‚   â””â”€â”€ MLoop/                           # Main CLI project
â”‚       â”œâ”€â”€ MLoop.csproj                 # Global tool configuration
â”‚       â”œâ”€â”€ Program.cs                   # Entry point
â”‚       â”‚
â”‚       â”œâ”€â”€ Commands/                    # CLI command handlers
â”‚       â”‚   â”œâ”€â”€ InitCommand.cs          # mloop init
â”‚       â”‚   â”œâ”€â”€ TrainCommand.cs         # mloop train
â”‚       â”‚   â”œâ”€â”€ PredictCommand.cs       # mloop predict
â”‚       â”‚   â”œâ”€â”€ EvaluateCommand.cs      # mloop evaluate
â”‚       â”‚   â”œâ”€â”€ ExperimentCommand.cs    # mloop experiment
â”‚       â”‚   â”œâ”€â”€ ModelCommand.cs         # mloop model
â”‚       â”‚   â””â”€â”€ ServeCommand.cs         # mloop serve (Phase 2)
â”‚       â”‚
â”‚       â”œâ”€â”€ Core/                        # Core business logic
â”‚       â”‚   â”œâ”€â”€ AutoML/                  # AutoML engine
â”‚       â”‚   â”‚   â”œâ”€â”€ ITrainingEngine.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ TrainingEngine.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ AutoMLRunner.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ TrainingConfig.cs
â”‚       â”‚   â”‚   â””â”€â”€ TrainingResult.cs
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ Data/                    # Data loaders
â”‚       â”‚   â”‚   â”œâ”€â”€ IDataLoader.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ CsvDataLoader.cs
â”‚       â”‚   â”‚   â””â”€â”€ JsonDataLoader.cs
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ Models/                  # Model management
â”‚       â”‚   â”‚   â”œâ”€â”€ IPredictionEngine.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ PredictionEngine.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ ModelLoader.cs
â”‚       â”‚   â”‚   â””â”€â”€ ModelSaver.cs
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ Evaluation/              # Evaluation
â”‚       â”‚       â”œâ”€â”€ IEvaluator.cs
â”‚       â”‚       â”œâ”€â”€ ClassificationEvaluator.cs
â”‚       â”‚       â””â”€â”€ RegressionEvaluator.cs
â”‚       â”‚
â”‚       â”œâ”€â”€ Infrastructure/              # Infrastructure
â”‚       â”‚   â”œâ”€â”€ FileSystem/              # Filesystem operations
â”‚       â”‚   â”‚   â”œâ”€â”€ IFileSystemManager.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ FileSystemManager.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ IProjectDiscovery.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ ProjectDiscovery.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ IExperimentStore.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ ExperimentStore.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ IModelRegistry.cs
â”‚       â”‚   â”‚   â””â”€â”€ ModelRegistry.cs
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ Configuration/           # Config management
â”‚       â”‚   â”‚   â”œâ”€â”€ MLoopConfig.cs
â”‚       â”‚   â”‚   â”œâ”€â”€ ConfigLoader.cs
â”‚       â”‚   â”‚   â””â”€â”€ ConfigMerger.cs
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ Logging/                 # Logging and progress
â”‚       â”‚       â”œâ”€â”€ IProgressReporter.cs
â”‚       â”‚       â””â”€â”€ SpectreProgressReporter.cs
â”‚       â”‚
â”‚       â””â”€â”€ Templates/                   # Project templates
â”‚           â”œâ”€â”€ binary-classification.yaml
â”‚           â”œâ”€â”€ multiclass-classification.yaml
â”‚           â””â”€â”€ regression.yaml
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ MLoop.Tests/                     # Unit tests
â”‚   â”‚   â”œâ”€â”€ Commands/
â”‚   â”‚   â”œâ”€â”€ Core/
â”‚   â”‚   â””â”€â”€ Infrastructure/
â”‚   â”‚
â”‚   â””â”€â”€ MLoop.IntegrationTests/          # Integration tests
â”‚       â””â”€â”€ EndToEndTests.cs
â”‚
â”œâ”€â”€ examples/                            # Example projects
â”‚   â”œâ”€â”€ sentiment-analysis/
â”‚   â”œâ”€â”€ iris-classification/
â”‚   â””â”€â”€ housing-prices/
â”‚
â”œâ”€â”€ docs/                                # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md                  # This file
â”‚   â”œâ”€â”€ getting-started.md
â”‚   â”œâ”€â”€ cli-reference.md
â”‚   â””â”€â”€ long-running-tasks.md           # nohup, screen guide
â”‚
â”œâ”€â”€ Directory.Build.props                # Common build properties
â”œâ”€â”€ .editorconfig                        # Code style
â”œâ”€â”€ nuget.config                         # NuGet configuration
â””â”€â”€ .gitignore                           # Git ignore rules
```

### 6.2 User Project Structure

When users run `mloop init my-project --task binary-classification`:

```
my-project/
â”œâ”€â”€ .mloop/                              # Internal (Git ignored)
â”‚   â”œâ”€â”€ config.json                      # Project settings
â”‚   â”œâ”€â”€ registry.json                    # Model registry index
â”‚   â””â”€â”€ experiment-index.json            # Experiment index
â”‚
â”œâ”€â”€ mloop.yaml                           # User config (optional, Git)
â”œâ”€â”€ .gitignore                           # MLoop gitignore
â”œâ”€â”€ README.md                            # Project guide
â”‚
â”œâ”€â”€ data/                                # User data (Git)
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â””â”€â”€ test.csv
â”‚   â””â”€â”€ predictions/                     # Prediction outputs
â”‚
â”œâ”€â”€ experiments/                         # Experiment results
â”‚   â”œâ”€â”€ exp-001/
â”‚   â”‚   â”œâ”€â”€ model.zip                    # Trained model (ignored)
â”‚   â”‚   â”œâ”€â”€ metadata.json                # Experiment metadata (Git)
â”‚   â”‚   â”œâ”€â”€ metrics.json                 # Performance metrics (Git)
â”‚   â”‚   â”œâ”€â”€ config.json                  # Training config (Git)
â”‚   â”‚   â””â”€â”€ training.log                 # Training log (ignored)
â”‚   â”œâ”€â”€ exp-002/
â”‚   â””â”€â”€ exp-003/
â”‚
â””â”€â”€ models/                              # Promoted models
    â”œâ”€â”€ staging/
    â”‚   â”œâ”€â”€ model.zip                    # (ignored)
    â”‚   â””â”€â”€ metadata.json                # (Git)
    â””â”€â”€ production/
        â”œâ”€â”€ model.zip                    # (ignored)
        â””â”€â”€ metadata.json                # (Git)
```

---

## 7. Data Models

### 7.1 Internal Management Files

#### .mloop/config.json
```json
{
  "project_name": "my-ml-project",
  "version": "0.1.0",
  "task": "binary-classification",
  "label_column": "Sentiment",
  "created_at": "2024-11-03T20:00:00Z",
  "mloop_version": "0.1.0-alpha"
}
```

#### .mloop/experiment-index.json
```json
{
  "next_id": 7,
  "experiments": [
    {
      "id": "exp-001",
      "timestamp": "2024-11-03T10:00:00Z",
      "status": "completed",
      "best_metric": 0.85
    },
    {
      "id": "exp-002",
      "timestamp": "2024-11-03T11:00:00Z",
      "status": "completed",
      "best_metric": 0.89
    }
  ]
}
```

#### .mloop/registry.json
```json
{
  "production": {
    "experiment_id": "exp-005",
    "promoted_at": "2024-11-03T21:00:00Z",
    "metrics": {
      "accuracy": 0.913,
      "f1_score": 0.897
    }
  },
  "staging": {
    "experiment_id": "exp-006",
    "promoted_at": "2024-11-03T22:00:00Z"
  }
}
```

### 7.2 Experiment Files

#### experiments/exp-XXX/metadata.json
```json
{
  "experiment_id": "exp-001",
  "timestamp": "2024-11-03T12:00:00Z",
  "status": "completed",
  "task": "binary-classification",
  "data": {
    "train_file": "data/processed/train.csv",
    "rows": 10000,
    "features": 15,
    "label": "Sentiment"
  },
  "config": {
    "time_limit_seconds": 300,
    "metric": "accuracy",
    "test_split": 0.2
  },
  "result": {
    "best_trainer": "LightGbmBinary",
    "training_time_seconds": 287
  },
  "versions": {
    "mlnet": "4.0.0",
    "mloop": "0.1.0-alpha"
  }
}
```

#### experiments/exp-XXX/metrics.json
```json
{
  "accuracy": 0.913,
  "f1_score": 0.897,
  "auc": 0.945,
  "precision": 0.901,
  "recall": 0.893
}
```

### 7.3 User Configuration File

#### mloop.yaml (optional)
```yaml
# MLoop Project Configuration
project_name: sentiment-analyzer
task: binary-classification
label_column: Sentiment

# Training settings (optional - defaults provided)
training:
  time_limit_seconds: 300
  metric: accuracy
  test_split: 0.2

# Data paths (optional)
data:
  train: data/processed/train.csv
  test: data/processed/test.csv

# Model output (optional)
model:
  output_dir: models/staging
```

---

## 8. Core Workflows

### 8.1 Project Initialization Workflow

```
User: mloop init my-project --task binary-classification
  â”‚
  â”œâ”€> Process Start
  â”‚
  â”œâ”€> CLI: Parse and validate command
  â”‚
  â”œâ”€> Core: InitCommand.ExecuteAsync()
  â”‚   â”‚
  â”‚   â”œâ”€> Create project directory structure
  â”‚   â”œâ”€> Initialize .mloop/ directory
  â”‚   â”œâ”€> Generate user files (mloop.yaml, .gitignore, README.md)
  â”‚   â””â”€> Save initial config
  â”‚
  â”œâ”€> CLI: Display success message
  â”‚
  â””â”€> Process Exit (return 0)
```

### 8.2 Training Workflow

```
User: mloop train data.csv --label target --time 600
  â”‚
  â”œâ”€> Process Start
  â”‚
  â”œâ”€> CLI: Parse command and validate inputs
  â”‚
  â”œâ”€> Core: TrainCommand.ExecuteAsync()
  â”‚   â”‚
  â”‚   â”œâ”€> ProjectDiscovery: Find project root (.mloop/)
  â”‚   â”‚
  â”‚   â”œâ”€> ExperimentStore: Generate new experiment ID
  â”‚   â”‚   â””â”€> Atomic update: experiment-index.json
  â”‚   â”‚
  â”‚   â”œâ”€> TrainingEngine: Execute AutoML
  â”‚   â”‚   â”œâ”€> Load and split data
  â”‚   â”‚   â”œâ”€> Run AutoML trials
  â”‚   â”‚   â”œâ”€> Stream progress to CLI (real-time)
  â”‚   â”‚   â””â”€> Select best model
  â”‚   â”‚
  â”‚   â””â”€> ExperimentStore: Save results
  â”‚       â”œâ”€> Create: experiments/exp-XXX/
  â”‚       â”œâ”€> Save: model.zip
  â”‚       â”œâ”€> Save: metadata.json
  â”‚       â”œâ”€> Save: metrics.json
  â”‚       â””â”€> Save: config.json
  â”‚
  â”œâ”€> CLI: Format and display results
  â”‚
  â””â”€> Process Exit (return 0)

# Process exited, all state in filesystem
# Next command starts fresh process
```

### 8.3 Prediction Workflow

```
User: mloop predict models/production/model.zip data.csv
  â”‚
  â”œâ”€> Process Start
  â”‚
  â”œâ”€> CLI: Parse command
  â”‚
  â”œâ”€> Core: PredictCommand.ExecuteAsync()
  â”‚   â”‚
  â”‚   â””â”€> PredictionEngine:
  â”‚       â”œâ”€> Load model.zip
  â”‚       â”œâ”€> Parse input data (CSV/JSON)
  â”‚       â”œâ”€> Execute batch predictions
  â”‚       â””â”€> Generate results
  â”‚
  â”œâ”€> CLI: Output results (console or file)
  â”‚
  â””â”€> Process Exit (return 0)
```

### 8.4 Concurrent Execution Example

```
Terminal 1                     Terminal 2
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
$ mloop train data.csv
  Process 1234 starts
  â””â”€> exp-001/
      [Training 40%...]
                               $ mloop train data.csv --metric f1
                                 Process 5678 starts
                                 â””â”€> exp-002/
                                     [Training 20%...]
      [Training 80%...]
                                     [Training 60%...]
  âœ… Complete, exit
  Process 1234 exits
                                     [Training 90%...]
                               âœ… Complete, exit
                               Process 5678 exits

Both experiments saved independently
No conflicts, no shared state
```

---

## 9. Configuration Management

### 9.1 Configuration Hierarchy

MLoop merges configuration from multiple sources with the following priority:

1. **CLI Arguments** (Highest Priority)
   - `--label`, `--time`, `--metric`, etc.

2. **mloop.yaml** (Project Level)
   - Project-specific defaults

3. **.mloop/config.json** (Created at init)
   - Initial project settings

4. **Hard-coded Defaults** (Lowest Priority)
   - Built-in default values

**Example Merge:**
```
CLI:           --time 600
mloop.yaml:    time_limit_seconds: 300, metric: f1
config.json:   task: binary-classification
defaults:      test_split: 0.2

Result (single process):
  time_limit_seconds: 600     (from CLI)
  metric: f1                  (from mloop.yaml)
  task: binary-classification (from config.json)
  test_split: 0.2            (from defaults)
```

---

## 10. Git Integration

### 10.1 Version Control Strategy

**Tracked (Committed to Git):**
- `.mloop/config.json` - Project configuration
- `.mloop/registry.json` - Model registry (metadata only)
- `experiments/*/metadata.json` - Experiment metadata
- `experiments/*/metrics.json` - Performance metrics
- `experiments/*/config.json` - Training configuration
- `models/*/metadata.json` - Promoted model metadata
- `mloop.yaml` - User configuration

**Ignored (Not committed):**
- `.mloop/cache/` - Temporary cache
- `experiments/*/model.zip` - Model binaries (large files)
- `experiments/*/training.log` - Detailed logs
- `models/*/model.zip` - Promoted model binaries
- `outputs/` - All output files

### 10.2 Collaboration Workflow

**Developer A (Run Experiment):**
```bash
$ mloop train data.csv --label price
$ git add experiments/exp-005/
$ git commit -m "Experiment 005: LightGBM, Acc=0.92"
$ git push
```

**Developer B (Review Experiment):**
```bash
$ git pull
$ mloop experiment show exp-005  # Read metadata.json, metrics.json
# Model binary can be retrained locally or shared separately
```

---

## 11. Technology Stack

### 11.1 Framework and Runtime

- **.NET 9.0**: Latest LTS version
- **C# 13**: Latest language features
- **Nullable Reference Types**: Enabled
- **Implicit Usings**: Enabled

### 11.2 Core Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| Microsoft.ML | 4.0.0 | ML.NET core framework |
| Microsoft.ML.AutoML | 0.21.1 | AutoML engine |
| System.CommandLine | 2.0.0-beta4 | CLI framework |
| YamlDotNet | 16.2.0 | YAML configuration |
| Spectre.Console | 0.49.1 | Rich CLI UI |

---

## 12. Testing Strategy

### 12.1 Unit Testing

**Scope:**
- Individual components in isolation
- Mock filesystem operations
- Interface-based dependency injection

### 12.2 Integration Testing

**Scope:**
- Multi-component interactions
- Real filesystem operations
- Concurrent execution scenarios

**Example: Concurrent Training Test**
```csharp
[Fact]
public async Task ConcurrentTraining_ShouldGenerateUniqueExperimentIds()
{
    using var tempDir = new TempDirectory();
    await InitProject(tempDir.Path);

    // Run two training jobs concurrently
    var task1 = RunTrainAsync(tempDir.Path, "data1.csv");
    var task2 = RunTrainAsync(tempDir.Path, "data2.csv");

    var results = await Task.WhenAll(task1, task2);

    // Both should succeed with different IDs
    Assert.NotEqual(results[0].ExperimentId, results[1].ExperimentId);
}
```

### 12.3 E2E Testing

**Scope:**
- Full CLI command execution
- Process lifecycle verification
- Multi-terminal concurrent execution

---

## 13. Long-Running Tasks

### 13.1 The Challenge

ML training can take minutes to hours. Users may need to:
- Close their terminal
- Disconnect from remote servers
- Run multiple training jobs
- Monitor progress remotely

### 13.2 Solution: Unix Tools (Not Daemon)

**Why not build a daemon?**
- âŒ Over-engineering for intermittent workloads
- âŒ Additional complexity (process management, ports, etc.)
- âŒ Standard Unix tools already solve this perfectly

**Recommended approaches:**

#### Option 1: nohup (Simple)

```bash
# Start training in background
$ nohup mloop train data.csv --label target --time 3600 > training.log 2>&1 &
[1] 12345

# Close terminal, training continues

# Check progress later
$ tail -f training.log

# Or check experiment files
$ cat experiments/exp-001/metadata.json
```

#### Option 2: screen (Interactive)

```bash
# Start screen session
$ screen -S ml-training

# Run training inside screen
$ mloop train data.csv --label target --time 3600
[Training...]

# Detach: Ctrl+A, then D
[detached from 12345.ml-training]

# Close terminal, training continues

# Reattach later
$ screen -r ml-training
[Training 80%...]
```

#### Option 3: tmux (Advanced)

```bash
# Create tmux session
$ tmux new -s ml-training

# Run training
$ mloop train data.csv --label target --time 3600

# Detach: Ctrl+B, then D

# Reattach later
$ tmux attach -t ml-training
```

### 13.3 Monitoring Progress

**Active monitoring (process running):**
```bash
# Real-time progress in terminal
$ mloop train data.csv --label target
ğŸ” AutoML Progress:
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% | 180s elapsed
```

**Post-execution monitoring:**
```bash
# Check experiment metadata
$ mloop experiment show exp-001

# View training log
$ tail -f experiments/exp-001/training.log

# Check metrics
$ cat experiments/exp-001/metrics.json | jq
```

### 13.4 Future: Optional --detach Flag (Phase 2)

If users really want built-in backgrounding:

```bash
# MLoop handles nohup internally
$ mloop train data.csv --label target --detach
âœ… Training started in background: exp-005
   PID: 12345
   Log: experiments/exp-005/training.log

# Check status
$ mloop experiment show exp-005
Status: in_progress (60% complete)

# Still just a process, not a daemon
# No mloop daemon start/stop/status
```

**Implementation:**
```csharp
if (detach)
{
    // Fork process with nohup
    var process = Process.Start(new ProcessStartInfo
    {
        FileName = "nohup",
        Arguments = $"mloop train {args}",
        RedirectStandardOutput = true,
        RedirectStandardError = true
    });

    Console.WriteLine($"Training started: PID {process.Id}");
    return 0; // Parent exits immediately
}
```

---

## 14. Future Extensibility

### 14.1 Why NOT Background Service (Phase 2)

**Original concern**: "Long training blocks CLI"

**Reality**:
- âœ… Unix tools (nohup, screen, tmux) solve this perfectly
- âœ… Users already familiar with these tools
- âœ… No need to reinvent process management
- âŒ Background daemon adds complexity
- âŒ MLoop workloads are intermittent, not continuous

**Decision**: Stick with multi-process model indefinitely

**If absolutely needed:** Add `--detach` flag (Phase 2), which internally uses `nohup`, not a daemon

### 14.2 Plugin System (Future)

**Potential Plugin Types:**
- Custom Trainers
- Data Loaders
- Storage Providers
- Metric Calculators

**Each plugin runs in-process:**
```csharp
public interface IPlugin
{
    string Name { get; }
    string Version { get; }
    void Initialize(IServiceProvider services);
}

// Loaded per-process, no shared state
var plugins = PluginLoader.Load(".mloop/plugins/");
foreach (var plugin in plugins)
{
    plugin.Initialize(services);
}
```

### 14.3 Remote Storage Support (Future)

**Filesystem abstraction enables remote storage:**

```csharp
public interface IStorageProvider
{
    Task<Stream> ReadAsync(string path);
    Task WriteAsync(string path, Stream content);
}

// Each process connects independently
var storage = config.StorageProvider switch
{
    "local" => new LocalStorageProvider(),
    "azure-blob" => new AzureBlobStorageProvider(),
    _ => throw new NotSupportedException()
};
```

**Multi-process still works:**
- Each process instance connects to storage
- No shared in-memory state
- Filesystem-like operations over network

---

## 15. Performance and Constraints

### 15.1 Target Scale

**Suitable:**
- Dataset size: < 1GB
- Training time: < 1 hour
- Concurrent experiments: Unlimited (filesystem isolated)
- Concurrent processes: Limited by system resources

**Process overhead:**
- Startup time: < 100ms
- Memory per process: ~50-200MB (ML.NET models)
- Acceptable for intermittent workloads

### 15.2 Filesystem Considerations

**Multi-process file locking:**
```csharp
// Atomic ID generation with retry
public async Task<string> GenerateExperimentIdAsync()
{
    for (int retry = 0; retry < 3; retry++)
    {
        try
        {
            // OS-level file locking
            using var fs = new FileStream(
                indexPath,
                FileMode.Open,
                FileAccess.ReadWrite,
                FileShare.None); // Exclusive lock

            var index = await ReadIndexAsync(fs);
            index.NextId++;
            await WriteIndexAsync(fs, index);
            return $"exp-{index.NextId:D3}";
        }
        catch (IOException)
        {
            // Another process has lock, retry
            await Task.Delay(100);
        }
    }
    throw new ConcurrencyException();
}
```

---

## 16. Security Considerations

### 16.1 Process Isolation

**Advantages:**
- âœ… Each command runs in separate process
- âœ… No shared memory between executions
- âœ… OS-level security boundaries
- âœ… Failed process doesn't affect others

### 16.2 Data Security

- Sensitive data in `.gitignore`
- Model encryption (future, if needed)
- No network exposure (except `mloop serve`)

---

## 17. Conclusion

MLoop's **multi-process casual design** perfectly matches its usage pattern and philosophy:

### 17.1 Core Principles

1. **Simplicity**: Each command = Independent process
2. **Transparency**: All state in filesystem, not daemon memory
3. **Isolation**: Natural process and filesystem boundaries
4. **Practicality**: Unix tools handle long-running tasks
5. **No Over-Engineering**: No daemon for intermittent workloads

### 17.2 Key Decisions

| Decision | Rationale |
|----------|-----------|
| **Multi-Process** | ML workloads are intermittent (train â†’ exit) |
| **No Daemon** | Unix tools (nohup, screen) solve long-running needs |
| **Filesystem State** | Enables natural isolation and Git integration |
| **In-Process Core** | Simpler than IPC, adequate for single-command execution |
| **Exception: serve** | Only API serving needs persistent process |

### 17.3 Future-Proof

- âœ… Plugin system: In-process loading
- âœ… Remote storage: Per-process connections
- âœ… Optional --detach: Internal nohup, not daemon
- âŒ Background service: Rejected as over-engineering

---

## Appendix A: Quick Reference

### A.1 Process Lifecycle

```
Command Invocation
    â†“
Process Start
    â†“
Load Configuration (from filesystem)
    â†“
Execute Core Logic
    â†“
Save Results (to filesystem)
    â†“
Process Exit
    â†“
No residual state in memory
```

### A.2 Key Commands (Phase 1)

| Command | Process Behavior |
|---------|------------------|
| `mloop init` | Start â†’ Create structure â†’ Exit |
| `mloop train` | Start â†’ Train â†’ Save â†’ Exit |
| `mloop predict` | Start â†’ Load â†’ Predict â†’ Exit |
| `mloop evaluate` | Start â†’ Load â†’ Evaluate â†’ Exit |
| `mloop serve` | Start â†’ Listen â†’ (User Ctrl+C) â†’ Exit |

### A.3 Concurrent Execution Patterns

```bash
# Same project, different experiments
Terminal 1: mloop train data.csv --time 300  â†’ exp-001
Terminal 2: mloop train data.csv --time 600  â†’ exp-002

# Different projects, any command
Terminal 1: cd project-A && mloop train ...
Terminal 2: cd project-B && mloop train ...

# All work perfectly, no conflicts
```

---

**Version**: 0.1.0-alpha
**Last Updated**: 2024-11-03
**Status**: Living Document
**Process Model**: Multi-Process Casual (Phase 1+)
