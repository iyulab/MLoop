# MLoop Environment Configuration
# Copy this file to .env and update with your actual credentials

# ==============================================================================
# LLM Provider Configuration (Choose one)
# ==============================================================================

# Option 1: GPUStack (Local OpenAI-compatible endpoint) - RECOMMENDED
# ------------------------------------------------------------------------------
# GPUStack provides local LLM serving with OpenAI-compatible API
# Ideal for on-premise deployment, data privacy, and cost control
GPUSTACK_ENDPOINT=http://172.30.1.53:8080
GPUSTACK_API_KEY=your_gpustack_api_key_here
GPUSTACK_MODEL=kanana-1.5

# Option 2: Anthropic Claude (Recommended for production)
# ------------------------------------------------------------------------------
# Anthropic Claude API for Claude 3/4 models (Opus, Sonnet, Haiku)
# Best-in-class reasoning, coding, and analysis capabilities
# Extended context: 200K tokens
# ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Alternative Anthropic models:
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022   # Claude 3.5 Sonnet (previous)
# ANTHROPIC_MODEL=claude-3-opus-20240229       # Most capable Claude 3
# ANTHROPIC_MODEL=claude-3-haiku-20240307      # Fastest, most affordable

# Option 3: OpenAI (Cloud-based)
# ------------------------------------------------------------------------------
# Official OpenAI API for GPT models
# OPENAI_API_KEY=sk-proj-your_openai_api_key_here
# OPENAI_MODEL=gpt-4o-mini

# Option 4: Azure OpenAI (Enterprise cloud)
# ------------------------------------------------------------------------------
# Azure-hosted OpenAI service with enterprise features
# AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com
# AZURE_OPENAI_KEY=your_azure_openai_key_here
# AZURE_OPENAI_MODEL=gpt-4

# ==============================================================================
# Priority Order
# ==============================================================================
# The application checks for credentials in this order:
# 1. GPUSTACK_ENDPOINT + GPUSTACK_API_KEY (preferred for local/on-premise)
# 2. ANTHROPIC_API_KEY (recommended for production Claude models)
# 3. AZURE_OPENAI_ENDPOINT + AZURE_OPENAI_KEY (fallback for Azure)
# 4. OPENAI_API_KEY (fallback for OpenAI cloud)

# ==============================================================================
# Usage Notes
# ==============================================================================
# - Only one set of credentials is needed
# - GPUStack is recommended for production on-premise deployments
# - Anthropic Claude is recommended for best-in-class AI reasoning and coding
# - Azure OpenAI is recommended for enterprise cloud deployments
# - OpenAI is recommended for development and prototyping
#
# Model Recommendations by Use Case:
# - Code Analysis & Generation: Claude Sonnet 4.5 (claude-sonnet-4-20250514)
# - Extended Context (200K tokens): Claude Sonnet 4.5 (Anthropic)
# - Cost-Effective Production: GPUStack (local) or Claude 3 Haiku (Anthropic)
# - Enterprise Compliance: Azure OpenAI (GPT-4)
# - Rapid Prototyping: OpenAI (GPT-4o-mini)
#
# Documentation:
# - Full configuration guide: docs/LLM_CONFIGURATION.md
# - Ironbees providers: https://github.com/iyulab/ironbees/blob/main/docs/PROVIDERS.md
# - Self-hosted setup: https://github.com/iyulab/ironbees/blob/main/docs/SELF_HOSTED_LLMS.md
#
# To use:
# 1. Copy this file: cp .env.example .env
# 2. Uncomment and fill in your chosen provider's credentials
# 3. Save the file (it's gitignored)
