# Equipment Anomaly Detection - MLoop Project Configuration
# Multi-model format (v0.2.0+)

project: equipment-anomaly-detection

# Model definitions
models:
  default:
    task: binary-classification
    label: IsError
    description: Equipment anomaly detection model
    training:
      time_limit_seconds: 600  # 10 minutes for better results with time-series data
      metric: F1Score  # F1-score for imbalanced anomaly detection
      test_split: 0.3  # 30% for validation (time-series requires larger validation set)

# Example: Multiple anomaly detection models
# models:
#   temperature:
#     task: binary-classification
#     label: TempAnomaly
#     description: Temperature anomaly detection
#   current:
#     task: binary-classification
#     label: CurrentAnomaly
#     description: Current anomaly detection

# Shared data paths
data:
  train: datasets/train.csv
  test: datasets/test.csv

# Feature engineering hints (informational)
# features:
#   numerical:
#     - Temp
#     - Current
#     - Hour
#     - Minute
#   categorical:
#     - Process
#
#   # Time-series specific considerations:
#   # - Rolling statistics (mean, std over time windows)
#   # - Lag features (previous N measurements)
#   # - Rate of change (delta Temp, delta Current)

# Model recommendations (informational)
# model_selection:
#   preferred_trainers:
#     - LightGBM        # Best for complex patterns
#     - FastTree        # Good for feature importance
#     - FastForest      # Robust to outliers

# Production deployment notes (informational)
# deployment:
#   latency_target: "<100ms"
#   monitoring:
#     - metric: "F1Score"
#       threshold: 0.75
#     - metric: "Precision"
#       threshold: 0.70
